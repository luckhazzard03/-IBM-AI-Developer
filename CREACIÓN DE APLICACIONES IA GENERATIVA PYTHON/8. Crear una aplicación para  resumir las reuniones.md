
Bienvenido a la descripción general del proyecto "Asistente de Reuniones con IA Generativa". Imagina que estás en una reunión de intercambio de ideas, donde las conversaciones fluyen rápidamente y se intercambian muchas piezas de información. Tienes que tomar notas, pero ¿puedes capturarlo todo? Luego, cuando intentas recordar decisiones clave o elementos de acción específicos, puede ser frustrante. Aquí es donde una aplicación innovadora y generativa basada en inteligencia artificial sería útil, ya que puede transcribir y resumir las discusiones de la reunión.

Imagina una aplicación que pueda transcribir las conversaciones de la reunión con precisión y luego proporcionar un resumen conciso, destacando los puntos clave y las decisiones tomadas. Este es el poder de combinar el reconocimiento automático de voz (ASR) y los modelos de lenguaje generativos (LLM) basados en IA. La tecnología ASR convierte el lenguaje hablado en texto legible, mientras que el LLM puede comprender y resumir el texto de manera eficiente. Además, el LLM puede refinar la salida de voz a texto, corrigiendo errores menores para garantizar un resultado coherente y preciso.

Este proyecto te guiará a través de la creación de una aplicación de este tipo. Utilizarás una herramienta de ASR llamada OpenAI Whisper para la conversión de voz a texto y aprovecharás las capacidades del modelo de lenguaje Llama 2, que se utilizará para resumir y extraer los puntos clave. Llama 2 es un modelo robusto de código abierto de Meta. El proyecto incluye instrucciones detalladas para crear e implementar la aplicación en un entorno sin servidor.

Primero, implementarás OpenAI Whisper para transcribir audio a texto utilizando un archivo de audio de muestra. Luego, crearás una interfaz intuitiva y fácil de usar para la aplicación mediante Hugging Face Gradio. Además, integrarás el LLM Llama 2, alojado en IBM watsonx, para resumir de manera efectiva el audio transcrito. IBM watsonx ofrece varios modelos de IA generativa, incluido Llama 2. Aprenderás a crear un script de Python para generar texto utilizando el modelo y algunos parámetros clave que influyen en la salida.

Finalmente, aprenderás a implementar la aplicación en línea usando IBM Code Engine, una plataforma sin servidor para ejecutar aplicaciones en la nube. Durante el proyecto, utilizarás Python para codificar diversas actividades. Se requiere un conocimiento básico de Python para poder llevar a cabo las tareas.

Al final del proyecto, habrás alcanzado varios objetivos clave. Explicarás cómo los LLM pueden ayudar a generar, refinar y resumir textos, implementarás la tecnología de reconocimiento automático de voz para convertir voz en texto, diseñarás una interfaz fácil de usar para la aplicación y la implementarás en una plataforma en la nube. Trabajar en este proyecto sentará una base sólida para utilizar los LLM en tareas de generación y resumen de textos, y te dará la oportunidad de demostrar tus habilidades de programación en Python para crear e implementar una aplicación que aproveche las capacidades de conversión de voz a texto de la IA y los modelos de IA generativa.

Este proyecto te permitirá aplicar y mejorar tus habilidades mientras desarrollas una aplicación útil y eficiente.

# IBM watsonx.ai



Bienvenido a IBM watsonx.ai. En este video, aprenderá las capacidades y características de IBM watsonx.ai, así como a identificar las herramientas comunes disponibles en esta plataforma. Aunque generar un poema, arte o una canción con IA es divertido, cuando la IA se aplica a los negocios, es necesario pensar a gran escala. La inteligencia artificial para las empresas debe construirse sobre estándares más elevados, asegurándose de ser confiable, segura, escalable y adaptable. Aquí es donde entra en juego la plataforma IBM watsonx, que ayuda a las empresas a aprovechar el poder de la IA.

IBM watsonx es una plataforma integrada de IA y datos destinada a los constructores de IA. La plataforma consta de tres productos principales. El primero es watsonx.ai, un estudio para nuevos modelos fundamentales, IA generativa y aprendizaje automático. El segundo es watsonx.data, un almacén de datos. Y el tercero es watsonx.governance, que ofrece un conjunto de herramientas para la supervisión y gobernanza de la IA. En este video, nos enfocaremos principalmente en watsonx.ai.

watsonx.ai es un conjunto de herramientas integradas impulsadas por modelos de base para trabajar con IA generativa y construir modelos de aprendizaje automático. Con watsonx.ai, puede entrenar, ajustar, desplegar y gestionar modelos fundamentales con facilidad, lo que le ayuda a construir aplicaciones de IA en una fracción del tiempo y con menos datos. Algunos de los objetivos clave que puede alcanzar con watsonx.ai incluyen la construcción de modelos de aprendizaje automático, la experimentación con modelos fundamentales y la gestión del ciclo de vida de la IA.

Dependiendo de su objetivo, puede seleccionar las tareas que ofrece watsonx.ai, las cuales se pueden realizar utilizando las herramientas proporcionadas en la plataforma. Las tareas y herramientas de watsonx.ai se alinean con el ciclo de vida de un modelo de IA: preparación de datos, creación de experimentos, entrenamiento de modelos y soluciones, despliegue de modelos y construcción de aplicaciones, así como la gestión de estos modelos y procesos repetitivos.

watsonx.ai ofrece acceso a modelos de código abierto seleccionados de Hugging Face, además de una familia de modelos base entrenados por IBM con diferentes tamaños y arquitecturas. Como creador de valor de IA, también puede aportar sus propios modelos y datos a watsonx.ai. Con herramientas como Prompt Lab, los creadores de IA pueden experimentar con modelos base y construir prompts que satisfagan sus necesidades. Prompt Lab permite experimentar con prompts para diversas tareas de procesamiento de lenguaje natural (PLN), como respuesta a preguntas, generación de contenido, resumen, clasificación y extracción de texto.

Si desea personalizar modelos según sus datos y necesidades empresariales, watsonx.ai le permite hacerlo mediante la herramienta Tuning Studio. Las versiones futuras de watsonx.ai incluirán métodos avanzados de ajuste rápido y ajuste fino de modelos base, mejorando el rendimiento y la precisión. Además, para gestionar y automatizar el ciclo de vida de los modelos, watsonx.ai ofrece la herramienta Pipeline. Esta herramienta ayuda a automatizar los pasos necesarios para cargar datos, entrenar modelos, desplegar modelos y evaluar su rendimiento. Esto reduce el tiempo necesario para poner un modelo en producción y mejora tanto la precisión como la fiabilidad de los modelos.

En este video, verá cómo las diversas herramientas de watsonx.ai crean un entorno colaborativo que agiliza el flujo de trabajo de los modelos de IA. Los modelos de IA solían entrenarse para tareas muy específicas, pero ahora, gracias al poder de los modelos base, es posible crear potentes aplicaciones de IA en una fracción del tiempo y con menos datos. En Prompt Lab, puede guiar a los modelos para satisfacer sus necesidades utilizando herramientas fáciles de usar para construir y refinar prompts que logren los resultados deseados.

Si desea personalizar aún más, puede adaptar los modelos para que sean aún más precisos para el caso de uso de su empresa. Con el Tuning Studio, puede traer conjuntos de datos y ajustar el modelo con solo 100 ejemplos, utilizando métodos de ajuste de última generación que se configuran con unos pocos clics. Finalmente, es el momento de poner su modelo en producción, desplegarlo a nivel empresarial y comenzar a desarrollar su aplicación.

En resumen, con watsonx.ai, su equipo se beneficiará de un entorno colaborativo que agiliza los flujos de trabajo a lo largo de todo el ciclo de vida de la IA, maximizando el poder de la IA para su empresa de manera práctica, eficiente y fácil de usar. Además, watsonx.ai garantiza la seguridad de los datos y los modelos que maneja, asegurando que su información esté protegida. Los datos y los modelos que cree son privados y solo accesibles para usted. IBM no tiene acceso a sus datos ni modelos, y estos nunca serán utilizados sin su permiso.

En este video, ha aprendido sobre IBM watsonx.ai, una plataforma de IA y datos que ayuda a las empresas a crear IA de manera responsable y transparente. Uno de los productos principales de watsonx es watsonx.ai, que es un estudio de herramientas integradas para entrenar, ajustar y desplegar modelos generativos de IA. Entre las herramientas destacadas se encuentran Prompt Lab, Tuning Studio y la herramienta Pipeline.


## Introducción a Meta Llama 2


**Objetivos**  
Después de completar esta lectura, podrá:

- Explicar las características clave de Llama 2.
- Demostrar ejemplos de uso de Llama 2 para el procesamiento de lenguaje natural.

**Introducción**  
Llama 2 es una familia de modelos de lenguaje de gran tamaño (LLMs) preentrenados y ajustados lanzados por Meta AI. Los modelos de IA Llama 2 son capaces de realizar una variedad de tareas de procesamiento de lenguaje natural (NLP), desde la generación de texto hasta la programación de código.

El modelo original Llama marcó un hito en el panorama de la IA generativa, ofreciendo capacidades para comprender y generar texto similar al humano. Fue diseñado para respaldar diversas aplicaciones, desde sistemas simples de preguntas y respuestas hasta tareas de procesamiento de lenguaje natural más complejas.

Sobre la base de los avances establecidos por sus predecesores, como el Generative Pretrained Transformer (GPT) y Llama, Meta Llama 2 introduce mejoras significativas en la comprensión y generación de texto similar al humano. Estos avances permiten que Meta Llama 2 maneje más datos, genere respuestas más precisas y coherentes, y lo haga más rápidamente y con menos recursos computacionales que el modelo Llama original. Estas mejoras facilitan una mejor comprensión de consultas complejas, generación de texto más matizada y contextualmente adecuada, y el soporte para una gama más amplia de idiomas.

Al aprovechar los avances más recientes en la investigación y la tecnología de IA, Meta Llama 2 tiene como objetivo superar las capacidades de modelos anteriores como GPT-3, BERT (Bidirectional Encoder Representations from Transformers) y el modelo Llama original, estableciendo un nuevo estándar en eficiencia y versatilidad para las tareas de procesamiento de lenguaje natural.

**Características clave de Meta Llama 2**

- **Mejora en comprensión y generación**: Llama 2 demuestra una capacidad superior para comprender y generar texto, lo que lo hace apto para manejar consultas complejas y generar respuestas coherentes y contextualmente relevantes.
- **Soporte multilingüe**: Llama 2 ofrece un amplio soporte para múltiples idiomas, lo que lo convierte en una herramienta versátil para aplicaciones globales.
- **Eficiencia en el procesamiento**: Con optimizaciones en la arquitectura del modelo, Llama 2 procesa información de manera más eficiente, lo que permite tiempos de respuesta más rápidos incluso para consultas complejas.
- **Personalización y escalabilidad**: Llama 2 puede ajustarse para tareas o industrias específicas, permitiendo que las empresas y los investigadores adapten sus capacidades a sus necesidades únicas.

**Aplicaciones de Meta Llama 2**  
La versatilidad de Meta Llama 2 permite su aplicación en una amplia gama de campos:

- **Creación de contenido**: Llama 2 puede ayudar o automatizar procesos de creación de contenido, desde la escritura de artículos hasta la generación de ficción creativa.
- **Análisis y resumen de datos**: Puede analizar rápidamente grandes volúmenes de texto y proporcionar resúmenes concisos, extrayendo información clave de los datos.
- **Traducción de idiomas**: Con sus capacidades multilingües, Llama 2 facilita la traducción fluida entre idiomas, mejorando la comunicación entre culturas.
- **Herramientas educativas**: El modelo puede alimentar sistemas de tutoría, ofreciendo experiencias de aprendizaje personalizadas y explicaciones a los estudiantes.

**Aspectos técnicos**  
La arquitectura de Llama 2 se basa en redes neuronales de transformadores, un tipo de modelo de aprendizaje profundo que ha revolucionado el campo del procesamiento de lenguaje natural. Al utilizar mecanismos de atención, Llama 2 puede centrarse en las partes relevantes de los datos de entrada, mejorando su capacidad para comprender y generar texto.

**Ejemplo 1: Generación de texto basada en un mensaje**  
Este ejemplo muestra cómo generar texto a partir de un mensaje utilizando Meta Llama 2. El ejemplo asume la existencia de un paquete de Python para interactuar con Llama 2, similar a cómo se usan los modelos de la biblioteca Hugging Face Transformers.

```python
from meta_llama import MetaLlama2
# Inicializar el modelo
model = MetaLlama2(model_name='meta-llama-2')
# Generar texto basado en un mensaje
prompt = "¿Cuál es el futuro de la inteligencia artificial?"
generated_text = model.generate_text(prompt)
print("Texto generado:", generated_text)
```

**Ejemplo 2: Resumen de datos**  
Este ejemplo muestra cómo Meta Llama 2 podría usarse para resumir un pasaje largo de texto en un resumen conciso. Esto es particularmente útil para extraer información clave de documentos grandes.

```python
from meta_llama import MetaLlama2
# Inicializar el modelo
model = MetaLlama2(model_name='meta-llama-2', task='summarization')
# Resumir texto
text = """La inteligencia artificial (IA) ha sido un tema de fascinación y una intensa investigación durante décadas. Las tecnologías de IA han evolucionado desde algoritmos básicos hasta modelos avanzados de aprendizaje automático, impactando profundamente en las industrias, la atención médica y la vida cotidiana. El futuro de la IA promete aún más cambios revolucionarios, con avances potenciales en vehículos autónomos, medicina personalizada y automatización inteligente."""
summary = model.summarize(text)
print("Resumen:", summary)
```

_Nota:_ En estos ejemplos, MetaLlama2 es una clase ficticia que representa la interacción con el modelo Meta Llama 2. En la realidad, la interacción con un modelo de este tipo dependería de la API o biblioteca específica proporcionada por los creadores del modelo. Los ejemplos están diseñados para ilustrar aplicaciones potenciales y deben adaptarse a los detalles de implementación reales de Meta Llama 2 o modelos similares disponibles a través de plataformas como Hugging Face Transformers.

**Conclusión**  
Meta Llama 2 se encuentra a la vanguardia de la IA generativa, ofreciendo un potencial transformador en diversas industrias. Sus avances en comprensión del lenguaje natural, eficiencia y versatilidad abren el camino para aplicaciones innovadoras, desde la mejora de la productividad en el lugar de trabajo hasta el impulso de la investigación.


## Introducción a OpenAI Whisper


**Objetivos**  
Después de completar esta lectura, podrá:

- Explicar las características clave de OpenAI Whisper.
- Identificar los casos de uso de OpenAI Whisper.
- Demostrar el código para configurar OpenAI Whisper e integrarlo en aplicaciones.

**Introducción**  
OpenAI Whisper es un sistema revolucionario de reconocimiento de voz diseñado para transcribir audio a texto con alta precisión. Basado en un modelo de aprendizaje profundo, Whisper demuestra una notable habilidad para manejar una amplia gama de tipos de audio, desde grabaciones claras de estudio hasta entornos ruidosos, y soporta múltiples idiomas. Esta flexibilidad hace que Whisper sea una herramienta invaluable para los desarrolladores que buscan integrar funcionalidades de voz en sus aplicaciones.

**Características clave de Whisper**

- **Alta precisión**: La precisión de Whisper es una de sus características más destacadas, lograda mediante el entrenamiento en un conjunto de datos diverso y extenso. Este conjunto incluye varios tipos de audio y escenarios, lo que permite que Whisper maneje diversos patrones de habla, acentos y dialectos con precisión. Gracias a su base en aprendizaje profundo, Whisper puede entender el contexto, mejorando su capacidad para transcribir con exactitud incluso cuando la calidad del audio es comprometida o el habla es poco clara.
- **Soporte multilingüe**: Whisper puede reconocer y transcribir el habla en numerosos idiomas. Entrenado con muestras de audio de una amplia variedad de idiomas, soporta transcripción multilingüe sin requerir selección manual de idioma. Esto lo hace versátil para aplicaciones globales, facilitando la comunicación y creación de contenido entre diferentes comunidades lingüísticas.
- **Robustez al ruido**: Una ventaja crítica de Whisper es su robustez en entornos ruidosos. Su entrenamiento incluye una variedad de muestras de audio ruidosas, lo que ayuda al modelo a distinguir efectivamente el habla del ruido de fondo. Esta característica es particularmente beneficiosa para aplicaciones en condiciones acústicas desafiantes, asegurando una transcripción confiable en situaciones que van desde entrevistas en calles concurridas hasta reuniones públicas ruidosas.

**Configuración de Whisper**  
Antes de profundizar en ejemplos de código y casos de uso, asegúrese de que su entorno de desarrollo esté listo para usar Whisper. Necesitará tener Python instalado en su sistema.

Para instalar Whisper, considere el siguiente comando:

```bash
pip install git+https://github.com/openai/whisper.git
```

**Ejemplo: Transcripción básica con Whisper**  
Comencemos con un ejemplo simple de transcripción de un archivo de audio a texto usando Whisper. Este ejemplo asume que tiene un archivo de audio llamado `audio_example.mp3`.

```python
import whisper
# Cargar el modelo Whisper
model = whisper.load_model("base")
# Transcribir el archivo de audio
result = model.transcribe("audio_example.mp3")
# Mostrar la transcripción
print(result["text"])
```

Este fragmento de código carga el modelo base de Whisper, transcribe el archivo de audio especificado y muestra la transcripción en la consola.

**Casos de uso en tiempo real**  
Whisper se puede aplicar en varios dominios para mejorar la accesibilidad, la eficiencia y la experiencia del usuario. Aquí hay algunos casos de uso en tiempo real:

- **Subtítulos automáticos para videos**: Mejore la accesibilidad del contenido de video en línea generando automáticamente subtítulos en múltiples idiomas.
- **Motores de búsqueda por voz**: Desarrolle motores de búsqueda que permitan a los usuarios realizar búsquedas usando comandos de voz, haciendo que la interfaz sea más accesible y fácil de usar.
- **Transcripciones de reuniones**: Transcriba automáticamente reuniones o conferencias en tiempo real, proporcionando valiosos registros basados en texto que pueden buscarse y referenciarse fácilmente.
- **Soporte al cliente multilingüe**: Use Whisper para transcribir llamadas de soporte al cliente, facilitando el soporte en múltiples idiomas y una análisis más fácil de los comentarios de los clientes.

**Características avanzadas**  
La versatilidad de Whisper permite personalización y optimización según requisitos específicos:

- **Modelos de lenguaje**: Whisper viene en varios tamaños (por ejemplo, tiny, base, small, medium, large). Los modelos más grandes ofrecen mayor precisión pero requieren más recursos computacionales.
- **Detección automática de idioma**: Whisper puede detectar automáticamente el idioma del audio, simplificando el proceso de transcripción para aplicaciones multilingües.

**Integración de Whisper en aplicaciones**  
La API de Python de Whisper facilita su integración en aplicaciones. A continuación, se presenta un ejemplo de código para crear un servicio web de transcripción con Flask.

```python
from flask import Flask, request
import whisper
app = Flask(__name__)
model = whisper.load_model("base")

@app.route("/transcribe", methods=["POST"])
def transcribe_audio():
    audio_file = request.files["audio"]
    result = model.transcribe(audio_file)
    return {"transcription": result["text"]}

if __name__ == "__main__":
    app.run(debug=True)
```

Esta simple aplicación Flask define un endpoint que acepta archivos de audio para su transcripción, demostrando cómo Whisper se puede integrar en aplicaciones web.

**Conclusión**  
OpenAI Whisper abre un mundo de posibilidades para los desarrolladores y empresas que buscan aprovechar el poder del reconocimiento de voz. Desde la creación de contenido más accesible hasta el desarrollo de servicios activados por voz, Whisper proporciona las herramientas necesarias para innovar y mejorar la experiencia del usuario en una amplia variedad de aplicaciones. Al explorar las capacidades de Whisper, considere cómo su integración puede mejorar sus proyectos y resolver desafíos reales.



![[Pasted image 20241213101207.png]]

![[Pasted image 20241213101303.png]]

![[Pasted image 20241213101313.png]]

![[Pasted image 20241213101323.png]]



# Introducción al proyecto: Babel Fish con LLM y STT TTS


En este proyecto, se desarrollará un asistente de traducción de IA con capacidad de voz, aprovechando el modelo flan-ul2 alojado en las bibliotecas de voz de IBM WatsonX.AI y Embeddable Watson. El asistente de voz tiene la capacidad de convertir la entrada de voz grabada en texto, enviar este texto al modelo flan-ul2 para su traducción y luego devolver una respuesta traducida en formato de texto. Posteriormente, esta respuesta se convierte en voz mediante la tecnología de conversión de texto a voz (TTS), permitiendo que el usuario escuche la traducción en el idioma deseado.

La interfaz del asistente incluye funcionalidades como un modo claro y oscuro, un cuadro de entrada para escribir mensajes, y un icono de micrófono. Los usuarios pueden escribir un mensaje o utilizar el micrófono para hablar en diferentes idiomas. Por ejemplo, al escribir "hola en francés" o decir "buenos días en español", el asistente responderá tanto en texto como en voz con la traducción correspondiente. Los usuarios pueden interactuar con este asistente a través de una interfaz web creada utilizando tecnologías como HTML, CSS y JavaScript.

El desarrollo del back-end del asistente se realizará utilizando Python y Flask para integrar el modelo flan-ul2. Además, se trabajará con IBM Watson X, una plataforma de datos e inteligencia artificial, que facilita la implementación de las bibliotecas de voz de IBM Watson. Estas bibliotecas permiten al asistente comunicarse mediante entrada y salida de voz.

Al combinar todos estos componentes, se creará un asistente de inteligencia artificial capaz de recibir entradas de voz y generar respuestas orales. Para este proyecto, es importante tener conocimientos en Python y Flask, y aunque no es obligatorio, se recomienda tener nociones básicas de HTML, CSS y JavaScript. Las instrucciones proporcionadas guiarán a los desarrolladores paso a paso en el proceso de creación del asistente de voz con herramientas de inteligencia artificial.

Al finalizar este proyecto, los participantes habrán adquirido las habilidades necesarias para crear un asistente de traducción impulsado por IA, capaz de procesar y traducir voz a texto y viceversa en varios idiomas. Además, obtendrán una base sólida en el desarrollo web utilizando Python, Flask, HTML, CSS y JavaScript, junto con una aplicación completamente funcional que será útil para todos los que interactúen con ella.


- IBM watsonx es una plataforma de IA y datos con un conjunto de asistentes de IA diseñados para ayudarle a escalar y acelerar el impacto de la IA con datos de confianza en toda su empresa.
    
- IBM Watson® Speech Libraries for Embed es un conjunto de bibliotecas de texto a voz y de voz a texto en contenedores diseñadas para ofrecer a nuestros socios de IBM una mayor flexibilidad para infundir lo mejor de la tecnología de IBM Research® en sus soluciones. Estas tecnologías permiten al asistente comunicarse con los usuarios a través de la entrada y salida de voz.
    
- Un asistente virtual es un programa diseñado para simular una conversación con usuarios humanos, especialmente a través de Internet, utilizando la voz humana natural.
    
- Puedes utilizar Python y Flask para construir el backend de tu asistente de voz.
    
- Las tecnologías HTML, CSS y JavaScript te permiten crear una interfaz visualmente atractiva e interactiva para tu asistente.
    

En el módulo, creaste un traductor de IA habilitado para voz y aprendiste:

- Cómo implementar la funcionalidad de voz a texto para que el asistente entienda la voz de los usuarios
    
- Cómo integrar el asistente con el modelo flan-ul2 de watsonx para dotarlo de un alto nivel de inteligencia y de la capacidad de comprender y responder a las peticiones de los usuarios
    
- Cómo implementar la función de conversión de texto a voz para que el asistente pueda comunicarse con los usuarios a través de la voz
    
- Cómo combinar todos los componentes para crear un asistente que funcione y sea capaz de recibir entradas de voz y ofrecer una respuesta hablada
    
- Cómo desplegar el asistente de voz en un servidor web para su uso por un público más amplio
    

![[Pasted image 20241213102120.png]]


![[Pasted image 20241213102129.png]]


![[Pasted image 20241213102138.png]]


![[Pasted image 20241213102145.png]]


**Glosario: Construcción de aplicaciones impulsadas por GenAI con Python**  
**cognitiveclass.ai logo**

¡Bienvenido! Este glosario en orden alfabético contiene muchos de los términos que encontrarás dentro de este curso. Este glosario integral también incluye términos adicionales reconocidos por la industria que no se usan en los videos del curso. Estos términos son importantes para que los reconozcas al trabajar en la industria, participar en grupos de usuarios y participar en otros programas de certificación.

|**Término**|**Definición**|
|---|---|
|Interfaz de Programación de Aplicaciones (API)|Una interfaz que facilita la comunicación entre aplicaciones. Las APIs ayudan a extraer y compartir datos utilizando un conjunto de definiciones y protocolos.|
|Pre-entrenamiento de Lenguaje-Imagen por Arranque (BLIP)|Un modelo basado en IA, utilizado para realizar tareas multimodales como respuestas a preguntas visuales, recuperación de imágenes y texto, y generación de descripciones de imágenes. Es un marco de pre-entrenamiento para una comprensión y generación unificada de visión y lenguaje.|
|BlenderBot|Un chatbot basado en IA que puede conversar de manera natural con las personas y recibe retroalimentación directa para mejorar sus respuestas.|
|Chatbot|Un programa de computadora que simula una conversación humana con un usuario final. Aunque no todos los chatbots están equipados con inteligencia artificial (IA), los chatbots modernos usan técnicas de IA conversacional como el procesamiento de lenguaje natural (NLP) para entender las preguntas del usuario y automatizar sus respuestas.|
|ChatGPT|Un chatbot desarrollado por OpenAI que usa grandes modelos de lenguaje (LLMs) para permitir que los usuarios interactúen y obtengan respuestas deseadas.|
|CodeT5|Un modelo de secuencia a secuencia (seq2seq) de texto a código desarrollado por Google AI, entrenado en un gran conjunto de datos de texto y código. CodeT5 es el primer modelo de lenguaje de programación preentrenado que es consciente del código y basado en un mecanismo codificador-decodificador.|
|Hojas de Estilo en Cascada (CSS)|Un lenguaje de computadora para diseñar y estructurar páginas web usando códigos.|
|Aprendizaje profundo (Deep learning)|Un tipo de aprendizaje automático centrado en entrenar a las computadoras para realizar tareas a través del aprendizaje de datos. Utiliza redes neuronales artificiales.|
|Falcon|Un modelo de lenguaje grande desarrollado por el Instituto de Tecnología de la Innovación (TII). Su variante, falcon-7b-instruct, es un modelo de 7 mil millones de parámetros basado en el modelo solo de decodificador.|
|Modelos base|Modelos de IA con amplias capacidades que pueden adaptarse para crear modelos o herramientas más especializados para casos de uso específicos.|
|Red Generativa Antagónica (GAN)|Un tipo de modelo generativo que incluye dos redes neuronales: generador y discriminador. El generador es entrenado con grandes conjuntos de datos para crear muestras como texto e imágenes. El discriminador trata de distinguir si la muestra es real o falsa.|
|Modelos de IA generativa|Modelos que pueden comprender el contexto del contenido de entrada para generar nuevo contenido. En general, se usan para la creación automatizada de contenido y la comunicación interactiva.|
|Transformador Generativo Pre-entrenado (GPT)|Una serie de grandes modelos de lenguaje desarrollados por OpenAI diseñados para comprender el lenguaje mediante una combinación de dos conceptos: entrenamiento y transformadores.|
|Google flan|Un modelo base codificador-decodificador basado en la arquitectura T5.|
|Gradio|Un paquete de Python de código abierto que permite crear una demostración o aplicación web para modelos de aprendizaje automático. Ayuda a crear interfaces de usuario (UI) para mostrar y desplegar modelos y compartirlos fácilmente.|
|Hugging Face|Una plataforma de IA que permite a científicos, emprendedores, desarrolladores e individuos colaborar y construir herramientas y modelos personalizados de aprendizaje automático.|
|Lenguaje de Marcado de Hipertexto (HTML)|Un lenguaje de marcado estándar que consta de elementos que crean y estructuran páginas web y ayudan a mostrarlas. Los elementos HTML se definen mediante una etiqueta de inicio, contenido y etiqueta de fin.|
|IBM Watson|Una plataforma integrada de IA y datos con un conjunto de asistentes de IA diseñados para escalar y acelerar el impacto de la IA con datos confiables en los negocios.|
|IBM Cloud Code Engine|Una plataforma completamente gestionada y sin servidor utilizada para gestionar y asegurar la infraestructura subyacente de códigos, imágenes de contenedores y trabajos por lotes.|
|Modelo de Lenguaje Grande (LLM)|Un modelo de aprendizaje profundo entrenado con una gran cantidad de datos textuales para aprender los patrones y estructuras del lenguaje. Pueden realizar tareas relacionadas con el lenguaje, como generación de texto, traducción, resumen, análisis de sentimientos y más.|
|Llama|Un modelo de lenguaje grande de Meta AI.|
|LlamaIndex|Un marco de datos flexible para conectar fuentes de datos personalizadas con modelos de lenguaje grande utilizando una interfaz central.|
|LangChain|Un marco diseñado para simplificar la creación de aplicaciones usando LLMs que ayudan en el análisis de documentos, resumen de documentos, construcción de chatbots y análisis de código.|
|Procesamiento de Lenguaje Natural (NLP)|Un subconjunto de la inteligencia artificial que permite que las computadoras comprendan, manipulen y generen lenguaje humano (lenguaje natural).|
|Reconocimiento de Entidades Nombradas (NER)|Una sub-tarea de extracción de información que ayuda a localizar y clasificar entidades nombradas como nombres y apellidos, ubicación geográfica, edad, dirección y número de teléfono en fuentes de datos no estructurados.|
|OpenAI Whisper|Un sistema de reconocimiento automático de voz entrenado con 680,000 horas de datos supervisados que puede transcribir el habla en varios idiomas.|
|Python|Un lenguaje de programación de alto nivel y propósito general que admite múltiples paradigmas de programación, incluidos la programación estructurada, orientada a objetos y funcional.|
|Biblioteca de Imágenes de Python (PIL)|Una versátil biblioteca de Python que agrega capacidades de procesamiento de imágenes al intérprete de Python y ayuda a realizar tareas como leer, cambiar el tamaño y guardar imágenes en diferentes formatos.|
|Generación Aumentada de Recuperación (RAG)|Un marco de IA diseñado para recuperar hechos de una base de conocimiento externa para respaldar modelos de lenguaje grande (LLMs) que proporcionan información sobre la última investigación, estadísticas o noticias a modelos generativos.|
|Análisis de Sentimientos|Un proceso de análisis de texto digital para determinar el tono emocional de un mensaje. Se realiza sobre datos textuales, ayudando a las empresas a monitorear marcas a través de comentarios de clientes.|
|Streamlit|Un marco de código abierto para construir y compartir aplicaciones web de aprendizaje automático y ciencia de datos. Convierte guiones de datos en aplicaciones web compartibles en minutos.|
|Tokenizador|Un tokenizador es una herramienta en procesamiento de lenguaje natural que descompone el texto en unidades más pequeñas y manejables (tokens), como palabras o frases, lo que permite que los modelos analicen y comprendan el texto.|
|Datos de Entrenamiento|Datos (generalmente grandes conjuntos de datos que también tienen ejemplos) utilizados para enseñar a un modelo de aprendizaje automático.|
|Transformadores|Una arquitectura de aprendizaje profundo que utiliza un mecanismo codificador-decodificador. Los transformadores pueden generar texto coherente y contextualizado.|
|Generación de Texto|Un modelo entrenado desde cero que ayuda a automatizar tareas repetitivas de codificación.|
|Aprendizaje No Supervisado|Un subconjunto de aprendizaje automático e inteligencia artificial que usa algoritmos basados en aprendizaje automático para analizar y agrupar conjuntos de datos no etiquetados. Estos algoritmos pueden descubrir patrones ocultos o agrupaciones de datos sin intervención humana.|
|Autoencoder Variacional (VAE)|Un modelo generativo que es una red neuronal diseñada para aprender la representación eficiente de los datos de entrada, codificándolos en un espacio más pequeño y decodificándolos de nuevo al espacio original.|
|watsonx.ai|Un estudio de herramientas integradas para trabajar con capacidades de IA generativa impulsadas por modelos base y construir modelos de aprendizaje automático.|
|watsonx.data|Un enorme repositorio de datos curados que se puede utilizar para entrenar y ajustar modelos con un sistema de gestión de datos de última generación.|
|watsonx.governance|Un conjunto de herramientas poderosas para dirigir, gestionar y monitorear las actividades de IA de tu organización.|











