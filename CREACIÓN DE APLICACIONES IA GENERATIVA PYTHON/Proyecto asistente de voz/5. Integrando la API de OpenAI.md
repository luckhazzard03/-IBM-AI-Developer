¡Es hora de darle un cerebro a tu asistente de voz! Con el poder de la API GPT-3.5 de OpenAI, puedes pasar el texto transcrito y recibir respuestas que contesten tus preguntas.

**Normalmente, necesitarías obtener una clave de API creando una cuenta en OpenAI, sin embargo, cuando usas nuestros laboratorios, esto ya se ha gestionado para que puedas continuar con tu proyecto sin preocuparte por ello.**

### Función de mensaje de proceso de OpenAI

Actualizarás la función llamada `openai_process_message`, que tomará un aviso y lo pasará a la API GPT-3 de OpenAI para recibir una respuesta. Esencialmente, es el equivalente a presionar el botón de enviar para obtener una respuesta de ChatGPT.

Adelante, actualiza la función `openai_process_message` en el archivo `worker.py` con lo siguiente:

 Open **worker.py** in IDE

### Worker.py



1. `def openai_process_message(user_message):`
2.     `# Set the prompt for OpenAI Api`
3.     `prompt = "Act like a personal assistant. You can respond to questions, translate sentences, summarize news, and give recommendations."`
4.     `# Call the OpenAI Api to process our prompt`
5.     `openai_response = openai_client.chat.completions.create(`
6.         `model="gpt-3.5-turbo",` 
7.         `messages=[`
8.             `{"role": "system", "content": prompt},`
9.             `{"role": "user", "content": user_message}`
10.         `],`
11.         `max_tokens=4000`
12.     `)`
13.     `print("openai response:", openai_response)`
14.     `# Parse the response to get the response message for our prompt`
15.     `response_text = openai_response.choices[0].message.content`
16.     `return response_text`


#### Explicación

La función es realmente simple, gracias a la biblioteca `openai` que es muy fácil de usar.

Aquí es donde puedes darle personalidad a tu asistente personal. En este caso, le estás diciendo al modelo que se convierta en un asistente personal al: `Act like a personal assistant`, y luego dándole tareas específicas que es capaz de realizar: `You can respond to questions, translate sentences, summarize news, and give recommendations.`. Al añadir el mensaje original del usuario después, le das a OpenAI más espacio para sonar genuino. Siéntete libre de cambiar esto según lo que necesites.

Luego llamas a la API de OpenAI utilizando la función `openai.chat.completions.create` y pasas los siguientes 3 parámetros:

1. `model`: Este es el modelo de OpenAI que queremos usar para procesar nuestro aviso, en este caso estamos usando su modelo _gpt-3.5-turbo_.
2. `messages`: El parámetro de mensajes es un arreglo de objetos que se utiliza para definir el flujo de conversación entre el usuario y la IA. Cada objeto representa un mensaje con dos atributos clave: rol (identificando al remitente como “system” para instrucciones de configuración o “user” para la consulta real del usuario) y contenido (el texto del mensaje). El mensaje de rol “system” instruye a la IA sobre cómo comportarse (por ejemplo, actuando como un asistente personal), mientras que el mensaje de rol “user” contiene la entrada del usuario. Este enfoque estructurado ayuda a personalizar las respuestas de la IA para que sean más relevantes y personalizadas.
3. `max_tokens`: Esta es la longitud máxima de la respuesta que estamos buscando. 30 tokens corresponden aproximadamente a 1-2 oraciones. En este momento, lo estamos configurando en 4000, que es el valor máximo de tokens que este modelo soporta.

Nuevamente, puedes ajustar definitivamente estos parámetros según tus necesidades personalizadas y puedes aprender más sobre ellos visitando [OpenAI playground](https://beta.openai.com/playground/p/default-marv-sarcastic-chat) donde puedes probar todos los parámetros en tiempo real.

La estructura de la respuesta es algo así:



1. `{`
2.   `"choices": [`
3.       `{"message": {`
4.           `content: "The model\'s answer to our prompt",`
5.           `...,`
6.           `...,`
7.       `},`
8.       `...,`
9.       `...`
10.     `]`
11. `}`


Por lo tanto, analizas la `openai_response` para extraer la respuesta a tu solicitud, que es `openai_response.choices[0].message.content`, y la almacenas en una variable llamada `response_text`. Finalmente, devuelves el `response_text`.

