

## Introducción

Imagina que estás asistiendo a una reunión de negocios donde todas las conversaciones están siendo capturadas por una aplicación avanzada de IA. Esta aplicación no solo transcribe las discusiones con alta precisión, sino que también proporciona un resumen conciso de la reunión, enfatizando los puntos clave y las decisiones tomadas.

En nuestro proyecto, utilizaremos Whisper de OpenAI para transformar el habla en texto. A continuación, usaremos la IA de IBM Watson para resumir y encontrar los puntos clave. Crearemos una aplicación con Hugging Face Gradio como interfaz de usuario.

### Objetivos de Aprendizaje

Después de finalizar este laboratorio, podrás:

- Crear un script en Python para generar texto utilizando un modelo del Hugging Face Hub, identificar algunos parámetros clave que influyen en la salida del modelo y tener una comprensión básica de cómo alternar entre diferentes modelos LLM.
- Utilizar la tecnología Whisper de OpenAI para convertir grabaciones de conferencias en texto, de manera precisa.
- Implementar la IA de IBM Watson para resumir efectivamente las conferencias transcritas y extraer puntos clave.
- Crear una interfaz intuitiva y fácil de usar utilizando Hugging Face Gradio, asegurando la facilidad de uso para estudiantes y educadores.

![langchain](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0V2VEN/images/DALL%C2%B7E%202024-02-29%2014.12.41%20-%20In%20a%20minimalist%20meeting%20room%20with%20a%20large%2C%20plain%20round%20table%2C%20a%20small%20and%20simple%20digital%20display%20is%20mounted%20on%20a%20white%20wall.%20The%20display%20shows%20%27Key%20Po.webp)

Generado por DALLE-3

## Preparando el entorno

Comencemos configurando el entorno creando un entorno virtual de Python e instalando las bibliotecas necesarias, utilizando los siguientes comandos en la terminal:



1. `pip3 install virtualenv` 
2. `virtualenv my_env # create a virtual environment my_env`
3. `source my_env/bin/activate # activate my_env`


Luego, instala las bibliotecas requeridas en el entorno (esto tomará tiempo ☕️☕️):



1. `# installing required libraries in my_env`
2. `pip install transformers==4.35.2 torch==2.1.1 gradio==4.44.0 langchain==0.0.343 ibm_watson_machine_learning==1.0.335 huggingface-hub==0.19.4`



Toma una taza de café, tomará unos minutos.



1.       `)  (`
2.      `(   ) )`
3.       `) ( (`
4.     `_______)_`
5.  `.-'---------|`  
6. `( C|/\/\/\/\/|`
7.  `'-./\/\/\/\/|`
8.    `'_________'`
9.     `'-------'`

Copied!

Necesitamos instalar `ffmpeg` para poder trabajar con archivos de audio en python.



1. `sudo apt update`



Luego ejecuta:



1. `sudo apt install ffmpeg -y`



> Whisper de OpenAI está disponible en [github](https://github.com/openai/whisper). El código y los pesos del modelo de Whisper se publican bajo la Licencia MIT. Consulta [LICENSE](https://github.com/openai/whisper/blob/main/LICENSE) para más detalles.



# Paso 1: De voz a texto

Inicialmente, queremos crear un archivo de Python simple de voz a texto utilizando OpenAI Whisper.

Puedes probar el archivo de audio de muestra **Muestra de voz [enlace para descargar.](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX04C6EN/Testing%20speech%20to%20text.mp3)**

Crea y abre un archivo de Python y llámalo `simple_speech2text.py` haciendo clic en el enlace a continuación:

 Open **simple_speech2text.py** in IDE

Primero, descarguemos el archivo (puedes hacerlo manualmente, luego arrástralo y suéltalo en el entorno de archivos).



1. `import requests`

3. `# URL of the audio file to be downloaded`
4. `url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX04C6EN/Testing%20speech%20to%20text.mp3"`

6. `# Send a GET request to the URL to download the file`
7. `response = requests.get(url)`

9. `# Define the local file path where the audio file will be saved`
10. `audio_file_path = "downloaded_audio.mp3"`

12. `# Check if the request was successful (status code 200)`
13. `if response.status_code == 200:`
14.     `# If successful, write the content to the specified local file path`
15.     `with open(audio_file_path, "wb") as file:`
16.         `file.write(response.content)`
17.     `print("File downloaded successfully")`
18. `else:`
19.     `# If the request failed, print an error message`
20.     `print("Failed to download the file")`



Ejecuta el archivo de Python para probarlo.



1. `python3 simple_speech2text.py`



Deberías ver el archivo de audio descargado en el explorador de archivos.

![langchain](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX04C6EN/images/whisper_download.jpg.jpg)

A continuación, implementa OpenAI Whisper para transcribir voz a texto.

Puedes sobrescribir el código anterior en el archivo de Python.



1. `import torch`
2. `from transformers import pipeline`

4. `# Initialize the speech-to-text pipeline from Hugging Face Transformers`
5. `# This uses the "openai/whisper-tiny.en" model for automatic speech recognition (ASR)`
6. ``# The `chunk_length_s` parameter specifies the chunk length in seconds for processing``
7. `pipe = pipeline(`
8.   `"automatic-speech-recognition",`
9.   `model="openai/whisper-tiny.en",`
10.   `chunk_length_s=30,`
11. `)`

13. `# Define the path to the audio file that needs to be transcribed`
14. `sample = 'downloaded_audio.mp3'`

16. `# Perform speech recognition on the audio file`
17. ``# The `batch_size=8` parameter indicates how many chunks are processed at a time``
18. ``# The result is stored in `prediction` with the key "text" containing the transcribed text``
19. `prediction = pipe(sample, batch_size=8)["text"]`

21. `# Print the transcribed text to the console`
22. `print(prediction)`



Ejecuta el archivo de Python y obtendrás la salida.



1. `python3 simple_speech2text.py`

Copied!Executed!

![langchain](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX04C6EN/images/whisper%20simple%20result.jpg)

En el siguiente paso, utilizaremos `Gradio` para crear la interfaz de nuestra aplicación.


