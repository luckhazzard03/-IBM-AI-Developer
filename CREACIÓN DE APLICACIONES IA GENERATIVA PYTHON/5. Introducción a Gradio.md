
### **Introducción a Gradio**

**Objetivos**  
Después de completar esta lectura, serás capaz de:

- Explicar los conceptos básicos de Gradio
- Demostrar un ejemplo de implementación de clasificación de imágenes en PyTorch

### **Introducción**

Gradio es la forma de demostrar tu modelo de aprendizaje automático con una interfaz web fácil de usar, de modo que cualquiera pueda utilizarlo en cualquier lugar. Gradio es un paquete de Python de código abierto que te permite crear rápidamente una demostración o aplicación web para tu modelo de aprendizaje automático, API o cualquier función arbitraria de Python. Luego, puedes compartir un enlace a tu demostración o aplicación web utilizando las funciones de compartición integradas de Gradio. No se requiere experiencia en JavaScript, CSS ni en alojamiento web.

### **¿Por qué usar Gradio?**

Gradio es útil por varias razones:

- **Facilidad de uso**: Gradio permite crear interfaces para modelos con solo unas pocas líneas de código.
- **Flexibilidad**: Gradio admite diversos tipos de entradas y salidas, como texto, imágenes, archivos, y más.
- **Compartir y colaborar**: Las interfaces pueden ser compartidas con otros a través de URL únicas, lo que facilita la colaboración y la recopilación de comentarios.

### **Comenzando con Gradio**

Para comenzar a usar Gradio, primero necesitas instalar la librería. Puedes instalar Gradio usando pip:

```bash
pip install gradio
```

### **Creando tu primera interfaz de Gradio**

Puedes ejecutar Gradio en tu editor de código favorito, Jupyter notebook, Google Colab o cualquier otro lugar donde escribas Python. Vamos a escribir tu primera aplicación Gradio:

```python
import gradio as gr

def greet(name, intensity):
    return "Hello, " + name + "!" * int(intensity)

demo = gr.Interface(
  fn=greet,
  inputs=["text", "slider"],
  outputs=["text"],
)

demo.launch()
```

Si lo ejecutas desde un archivo, la demostración se abrirá en un navegador en `http://localhost:7860`. Si lo estás ejecutando dentro de un cuaderno, la demostración aparecerá incrustada dentro del cuaderno.


![[Pasted image 20241211121046.png]]

Escriba su nombre en el cuadro de texto de la izquierda, arrastre el control deslizante y luego presione el botón Enviar. Deberías ver un saludo amistoso a la derecha.

![[Pasted image 20241211121130.png]]


### **Entendiendo la clase Interface**

**Nota**: Para crear tu primera demostración, creaste una instancia de la clase `gr.Interface`. La clase `Interface` está diseñada para crear demostraciones de modelos de aprendizaje automático que aceptan una o más entradas y devuelven una o más salidas.

La clase `Interface` tiene tres argumentos principales:

- **fn**: La función a la que se le aplicará una interfaz de usuario (UI).
- **inputs**: El/los componente(s) de Gradio a utilizar para la entrada. El número de componentes debe coincidir con el número de argumentos en tu función.
- **outputs**: El/los componente(s) de Gradio a utilizar para la salida. El número de componentes debe coincidir con el número de valores de retorno de tu función.

El argumento **fn** es flexible: puedes pasar cualquier función de Python que desees envolver con una interfaz de usuario. En el ejemplo anterior, viste una función relativamente simple, pero la función podría ser cualquier cosa, desde un generador de música hasta un calculador de impuestos o la función de predicción de un modelo de aprendizaje automático preentrenado.

Los argumentos de entrada y salida toman uno o más componentes de Gradio. Como veremos, Gradio incluye más de 30 componentes integrados (como `gr.Textbox()`, `gr.Image()`, y `gr.HTML()`) diseñados para aplicaciones de aprendizaje automático.

Si tu función acepta más de un argumento, como en el ejemplo anterior, pasa una lista de componentes de entrada a `inputs`, con cada componente de entrada correspondiente a uno de los argumentos de la función en orden. Lo mismo ocurre si tu función devuelve más de un valor: simplemente pasa una lista de componentes a `outputs`. Esta flexibilidad hace que la clase `Interface` sea una forma muy poderosa de crear demostraciones.

### **Creando una interfaz simple para un modelo de descripción de imágenes**

El modelo **BLIP** (Bootstrapped Language Image Pretraining) puede generar descripciones para imágenes. Aquí te mostramos cómo puedes crear una interfaz Gradio para el modelo BLIP.

1. Instala la librería `transformers`:

```bash
pip install transformers
```

2. Código para crear la interfaz:

```python
import gradio as gr
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image

# Cargar el procesador y el modelo preentrenado
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

def generate_caption(image):
    # Usamos directamente el objeto PIL Image
    inputs = processor(images=image, return_tensors="pt")
    outputs = model.generate(**inputs)
    caption = processor.decode(outputs[0], skip_special_tokens=True)
    return caption

def caption_image(image):
    """
    Toma una imagen PIL como entrada y devuelve una descripción.
    """
    try:
        caption = generate_caption(image)
        return caption
    except Exception as e:
        return f"Se produjo un error: {str(e)}"

iface = gr.Interface(
    fn=caption_image,
    inputs=gr.Image(type="pil"),
    outputs="text",
    title="Generación de descripciones de imágenes con BLIP",
    description="Sube una imagen para generar una descripción."
)

iface.launch()
```

En este ejemplo, usamos `BlipProcessor` y `BlipForConditionalGeneration` de la librería `transformers` para configurar un modelo de descripción de imágenes. Este ejemplo muestra cómo crear una interfaz web usando Gradio, donde el parámetro de entrada especifica una imagen y la salida es la descripción generada en texto. Los parámetros `title` y `description` mejoran la interfaz proporcionando contexto e instrucciones para los usuarios.

### **Caso de uso: Descripción de imágenes**

Los modelos de descripción de imágenes, como BLIP, son herramientas increíblemente poderosas en diversos dominios, desde ayudar a personas con discapacidades visuales a entender el contenido de las imágenes hasta organizar y buscar eficientemente en grandes bibliotecas de fotos. Crear una interfaz Gradio para este tipo de modelos lo hace accesible para usuarios no técnicos, lo que les permite interactuar con esta tecnología. Por ejemplo, fotógrafos o gerentes de activos digitales podrían usar tu aplicación para generar nombres descriptivos automáticamente para sus imágenes, mejorando la usabilidad y la capacidad de búsqueda de sus bibliotecas digitales.

---

### **Clasificación de imágenes en PyTorch**

La clasificación de imágenes es una tarea central en la visión por computadora. Crear mejores clasificadores para identificar qué objeto está presente en una imagen es un área activa de investigación, ya que tiene aplicaciones que van desde vehículos autónomos hasta imágenes médicas.

Estos modelos son perfectos para usarse con el componente de entrada de imágenes de Gradio. En este tutorial, vamos a crear una demostración web para clasificar imágenes usando Gradio. Podemos construir toda la aplicación web en Python.

#### **Paso 1: Configuración del modelo de clasificación de imágenes**

Primero, necesitamos un modelo de clasificación de imágenes. Para este tutorial, usaremos un modelo preentrenado **ResNet-18**, ya que es fácilmente descargable desde PyTorch Hub. Puedes usar un modelo diferente o entrenar el tuyo propio.

```python
import torch
model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()
```

#### **Paso 2: Definir una función de predicción**

Luego, debemos definir una función que reciba la entrada del usuario, que en este caso es una imagen, y devuelva la predicción. La predicción debe ser devuelta como un diccionario cuyos claves sean el nombre de la clase y los valores sean las probabilidades de confianza. Cargaremos los nombres de las clases desde un archivo de texto.

En el caso de nuestro modelo preentrenado, se verá así:

```python
import requests
from PIL import Image
from torchvision import transforms

# Descargar etiquetas legibles para ImageNet.
response = requests.get("https://git.io/JJkYN")
labels = response.text.split("\n")

def predict(inp):
    inp = transforms.ToTensor()(inp).unsqueeze(0)
    with torch.no_grad():
        prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)
        confidences = {labels[i]: float(prediction[i]) for i in range(1000)}
    return confidences
```

Vamos a desglosar esto. La función toma un parámetro:

- **inp**: la imagen de entrada como una imagen PIL.

La función convierte la imagen de entrada en una imagen PIL y posteriormente en un tensor de PyTorch. Después de procesar el tensor a través del modelo, devuelve las predicciones en forma de un diccionario llamado **confidences**. Las claves del diccionario son las etiquetas de clase y sus valores son las probabilidades correspondientes.

En esta sección, definimos una función de predicción que procesa una imagen de entrada para devolver las probabilidades de predicción. La función primero convierte la imagen en un tensor de PyTorch y luego la pasa a través del modelo preentrenado. Usamos la función **softmax** en el último paso para calcular las probabilidades de cada clase.

#### **Paso 3: Crear una interfaz Gradio**

Ahora que tenemos nuestra función predictiva configurada, podemos crear una interfaz Gradio alrededor de ella.

En este caso, el componente de entrada será una imagen de arrastrar y soltar. Para crear este componente de entrada, usamos `Image(type="pil")`, que crea el componente y maneja el procesamiento para convertirlo en una imagen PIL.

El componente de salida será una etiqueta que muestra las mejores etiquetas de una forma bonita. Como no queremos mostrar todas las 1,000 etiquetas de clase, lo personalizaremos para mostrar solo las tres primeras imágenes, construyéndolo como `Label(num_top_classes=3)`.

Finalmente, agregaremos un parámetro más, **examples**, que nos permite pre-poblar nuestras interfaces con algunos ejemplos predefinidos. El código de Gradio se verá así:

```python
import gradio as gr
gr.Interface(fn=predict,
       inputs=gr.Image(type="pil"),
       outputs=gr.Label(num_top_classes=3),
       examples=["/content/lion.jpg", "/content/cheetah.jpg"]).launch()
```

Los ejemplos proporcionados, `/content/lion.jpg` y `/content/cheetah.jpg`, son ejemplos de rutas. Debes reemplazarlos con las rutas reales de las imágenes en tu sistema o servidor donde hayas guardado las imágenes que deseas usar para probar. Esto asegura que cuando tú o otros usen la interfaz Gradio, los ejemplos se carguen correctamente y se pueda demostrar la funcionalidad de tu clasificador de imágenes.

Esto producirá la siguiente interfaz, que puedes probar en un navegador (intenta subir tus propios ejemplos).



![[Pasted image 20241211121254.png]]

![[Pasted image 20241211121305.png]]



¡Y ya está! Ese es todo el código que necesita para crear una demostración web de un clasificador de imágenes. Si desea compartir con otras personas, intente configurar share=True cuando inicie() la interfaz.

#### Conclusión

Gradio simplifica el proceso de creación de demostraciones web interactivas para modelos de aprendizaje automático. Al integrar Gradio con modelos como BLIP para subtítulos de imágenes, puede crear aplicaciones prácticas y fáciles de usar que aprovechan el poder de la IA para resolver problemas del mundo real. Esta herramienta no sólo ayuda a demostrar las capacidades de sus modelos, sino también a recopilar comentarios valiosos para seguir mejorando.

- La IA de subtitulado de imágenes permite transformar la información visual de las imágenes en lenguaje legible por máquina.
    
- Al transformar los datos visuales en texto, la IA de subtitulación de imágenes allana el camino para un descubrimiento de contenidos más profundo, una presencia atractiva en las redes sociales y una gestión eficaz de los datos en diversos campos.
    
- El modelo Bootstrap Language-Image Pre-training (BLIP) puede realizar varias tareas multimodales, como la recuperación de texto de imágenes y el subtitulado de imágenes.
    
- Gradio es un paquete de Python de código abierto que permite crear una aplicación web o de demostración para un modelo de Aprendizaje automático o una función de Python. Gradio admite varias entradas y salidas, como texto, imágenes, archivos, etc.
    

En este módulo, has trabajado en un proyecto para construir una IA que analiza imágenes, genera descripciones y crea un índice de texto para ellas. Este proyecto implica:

- Implementar una herramienta de subtitulado de imágenes utilizando el modelo BLIP de Transformadores de Hugging Face.
    
- Utilizar Gradio para proporcionar una interfaz fácil de usar para nuestra aplicación de subtitulado de imágenes.
    
- Adaptar la herramienta a escenarios empresariales reales, demostrando sus aplicaciones prácticas.
    

![[Pasted image 20241211162920.png]]

![[Pasted image 20241211162932.png]]


![[Pasted image 20241211162948.png]]

![[Pasted image 20241211162958.png]]



