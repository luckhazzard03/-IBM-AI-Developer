

En este módulo, se abordarán los conceptos fundamentales del análisis exploratorio de datos con Python. El análisis exploratorio de datos, o EDA (Exploratory Data Analysis, por sus siglas en inglés), es una metodología para examinar un conjunto de datos con el objetivo de resumir sus características principales y obtener una comprensión más profunda de los mismos. A través de EDA, buscamos descubrir relaciones entre las variables y extraer las que son más relevantes para el problema que estamos tratando de resolver. La pregunta central que trataremos de responder es: ¿cuáles son las características que más influyen en el precio de un coche?

A lo largo del módulo, exploraremos diversas técnicas de análisis exploratorio de datos que nos ayudarán a responder a esta pregunta. Una de estas técnicas es la estadística descriptiva, que se utiliza para describir las características fundamentales de un conjunto de datos y proporcionar un resumen conciso de las muestras y las medidas de los datos. También veremos cómo agrupar datos utilizando el método **GroupBy**, que permite transformar y agrupar el conjunto de datos en categorías específicas para un análisis más detallado.

Además, se cubrirá el análisis de la varianza o **ANOVA**, una técnica estadística que divide la variación de un conjunto de observaciones en diferentes componentes, lo que facilita la comprensión de cómo varían los datos. También se discutirá la **correlación entre variables**, una herramienta clave para entender cómo se relacionan entre sí las diferentes características. Finalmente, nos adentraremos en técnicas más avanzadas de correlación, como los mapas térmicos de correlación y la **correlación de Pearson**, que son útiles para evaluar de manera más precisa la relación entre las variables en el conjunto de datos.



# Estadística descriptiva


En este vídeo, se aborda el tema de la **estadística descriptiva**, una parte fundamental del análisis exploratorio de datos. Antes de dedicar tiempo a crear modelos complejos, es crucial explorar los datos de manera sencilla y eficiente. Una forma de hacerlo es calcular estadísticas descriptivas para obtener un resumen general de las características básicas del conjunto de datos. El análisis estadístico descriptivo ayuda a resumir los datos mediante medidas clave, como la media, la desviación estándar, los cuartiles y los valores atípicos, proporcionando así una visión más clara de la distribución de las diferentes variables.

Uno de los métodos más útiles en Python para obtener un resumen de los datos es la función `describe()` de pandas. Al aplicarla a un dataframe, esta función calcula automáticamente las estadísticas básicas para todas las variables numéricas. Entre las estadísticas que muestra están la media, el número total de puntos de datos, la desviación estándar, los cuartiles y los valores extremos. Además, los valores faltantes (NaN) se omiten automáticamente. Esto proporciona una visión general de cómo se distribuyen los datos y qué características son más relevantes. También podemos encontrarnos con variables categóricas, como la variable de tracción en un conjunto de datos de coches. Estas variables tienen valores discretos y se pueden dividir en diferentes categorías. Un ejemplo en el conjunto de datos de coches es el sistema de tracción, que puede ser tracción delantera, trasera o a las cuatro ruedas.

Para resumir los datos de las variables categóricas, podemos usar la función `value_counts()`. Esto nos da la frecuencia de cada categoría. Por ejemplo, si aplicamos `value_counts()` a la variable "tracción", podemos ver cuántos coches hay en cada categoría: 118 coches con tracción delantera, 75 con tracción trasera y 8 con tracción a las cuatro ruedas. Esta función facilita la comprensión de cómo se distribuyen las categorías en el conjunto de datos. Los diagramas de caja (boxplots) son otra herramienta excelente para visualizar datos numéricos. Estos diagramas muestran la mediana de los datos, los cuartiles y los valores atípicos. La caja central representa el rango intercuartílico, es decir, los valores entre el cuartil 25 y el cuartil 75. Los puntos fuera de los extremos de la caja indican valores atípicos.

Los diagramas de caja son especialmente útiles para comparar la distribución de datos entre diferentes grupos. Por ejemplo, en un conjunto de datos de coches, podemos usar un diagrama de caja para comparar el precio de los coches según el tipo de tracción. Al hacerlo, podemos observar que el precio de los coches con tracción trasera se distribuye de manera diferente al de los coches con tracción delantera o a las cuatro ruedas. Esto puede ser indicativo de una influencia de la tracción en el precio del coche.

A menudo, también nos encontramos con **variables continuas** en los datos, como el precio y el tamaño del motor de un coche. Para explorar la relación entre estas dos variables, podemos usar un **diagrama de dispersión (scatter plot)**. Este tipo de gráfico nos permite visualizar la relación entre dos variables. En este caso, el tamaño del motor es la variable predictora (en el eje X) y el precio es la variable objetivo (en el eje Y). Al observar el diagrama de dispersión, podemos notar que, en general, a medida que aumenta el tamaño del motor, también lo hace el precio del coche, lo que sugiere una relación lineal positiva entre ambas variables. Es importante recordar etiquetar los ejes y añadir un título a la gráfica para una correcta interpretación de los datos.

# Comandos de Visualización de Datos en Python

![cognitiveclass.ai](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/images/image.png)

#### Esfuerzo Estimado: 20 minutos

Las visualizaciones juegan un papel clave en el análisis de datos. En esta lectura, se te presentarán diversas formas de gráficos y diagramas que puedes crear con tus datos en Python que te ayudarán a visualizar tus datos para un mejor análisis.

Las dos principales bibliotecas utilizadas para crear gráficos son **matplotlib** y **seaborn**. Aprenderemos las funciones de gráficos más destacadas de ambas bibliotecas en relación con el Análisis de Datos.

## Importando bibliotecas

Puedes importar las bibliotecas mencionadas arriba como se muestra a continuación.

**a. matplotlib**


```python
from matplotlib import pyplot as plt
```

Alternativamente, el comando también se puede escribir como:

```python
import matplotlib.pyplot as plt
```

Tenga en cuenta que la mayoría de los gráficos que nos interesan en esta biblioteca se encuentran en la subcarpeta `pyplot` del paquete.

Las funciones de `matplotlib` devuelven un objeto de gráfico que requiere declaraciones adicionales para mostrarse. Al usar `matplotlib` en Jupyter Notebooks, necesitamos que el gráfico se muestre dentro de la interfaz del notebook. Por lo tanto, es esencial agregar la siguiente declaración ‘mágica’ después de cargar la biblioteca.


```python
1. `   %matplotlib inline`
```


**b. seaborn**  
Seaborn se suele importar en un código utilizando la siguiente declaración:

```python
import seaborn as sns
```

## funciones de matplotlib

**1. Gráfico de líneas estándar**

El gráfico más simple y fundamental es un gráfico de líneas estándar. La función espera dos arreglos como entrada, `x` e `y`, ambos del mismo tamaño. `x` se trata como una variable independiente y `y` como la dependiente. El gráfico se traza como segmentos de línea más cortos que unen los pares de puntos `x,y` ordenados en función de la variable `x`.

**Sintaxis:**



```python
plt.plot(x,y)
```


A continuación se muestra un gráfico de ejemplo en la imagen de abajo.


![[Pasted image 20241227121401.png]]



**2. Gráfico de dispersión**

Los gráficos de dispersión son gráficos que presentan la relación entre dos variables en un conjunto de datos. Representa puntos de datos en un plano bidimensional. La variable independiente o atributo se representa en el eje X, mientras que la variable dependiente se representa en el eje Y.

Los gráficos de dispersión se utilizan en cualquiera de las siguientes situaciones:

- Cuando tenemos datos numéricos emparejados
- Cuando hay múltiples valores de la variable dependiente para un valor único de una variable independiente
- Para determinar la relación entre variables en algunos escenarios

**Sintaxis:**


```python 
plt.scatter(x,y)

```



Aquí, `x` contiene la variable independiente, y `y` contiene la variable dependiente. Tienes la opción de cambiar el tamaño, color y forma de los marcadores con atributos adicionales en la función. A continuación se comparte un ejemplo de gráfico de dispersión.


![[Pasted image 20241227121448.png]]

**3. Histograma**

Un histograma es una representación visual importante de los datos en forma categórica. Para ver los datos en una forma “Agrupada”, podemos utilizar el gráfico de histograma con el número de grupos requeridos o incluso con los puntos de datos que marcan los bordes de los grupos. El eje x representa los grupos de datos, y el eje y representa el número de elementos en cada uno de los grupos.

**Sintaxis:**



```python
plt.hist(x,bins)
```

Un ejemplo de un gráfico de histograma se muestra a continuación. Utilice un argumento adicional, `edgecolor`, para mejorar la claridad del gráfico.  
Considere el gráfico que se muestra a continuación. El gráfico de la izquierda es el gráfico de histograma para un conjunto de datos, trazado sin establecer el `edgecolor`. El de la derecha es el mismo gráfico, pero tiene el argumento `edgecolor` configurado como el color `negro`.



![[Pasted image 20241227141626.png]]

**4. Gráfico de barras**

Un gráfico de barras se utiliza para visualizar datos categóricos. El eje y representa el valor promedio de los puntos de datos que pertenecen a una categoría particular, mientras que el eje x representa el número de elementos en las diferentes categorías.

**Sintaxis:**


```python
plt.bar(x,height)

```


Aquí, `x` es la variable categórica, y `height` es el número de valores que pertenecen a la categoría. Puedes ajustar el ancho de cada bin utilizando un argumento adicional `width` en la función.

A continuación se muestra un gráfico de muestra.



![[Pasted image 20241227141711.png]]


**5. Gráfico de Pseudocolor**

Un gráfico de pseudocolor muestra datos de matriz como un conjunto de celdas coloreadas (conocidas como caras). Este gráfico se crea como una superficie plana en el plano x-y. La superficie está definida por una cuadrícula de coordenadas x e y que corresponden a las esquinas (o vértices) de las caras. La matriz C especifica los colores en los vértices. El color de cada cara depende del color de uno de sus cuatro vértices circundantes. De los cuatro vértices, el que aparece primero en la cuadrícula x-y determina el color de la cara.

En este curso, utilizas el gráfico pcolor para visualizar el contenido de una tabla dinámica que ha sido agrupada en función de 2 parámetros. Esos parámetros representan los componentes del eje x e y que crean la cuadrícula. Los valores en la tabla dinámica son los valores promedio de un tercer parámetro. Estos valores actúan como el código para el color que tomará la celda.

**Sintaxis:**

```python
git push -u origin main

```


Puedes definir un argumento adicional `cmap` para especificar el esquema de color del gráfico.

A continuación se muestran dos ejemplos de gráficos pcolor, creados con los mismos datos pero con diferentes esquemas de color.


![[Pasted image 20241230121552.png]]


## funciones de seaborn

**1. Gráfico de regresión**

Un gráfico de regresión traza un diagrama de dispersión de dos variables, x e y, y luego ajusta el modelo de regresión y traza la línea de regresión resultante junto con un intervalo de confianza del 95% para esa regresión. Los parámetros x e y se pueden compartir como los encabezados del dataframe a utilizar, y el propio dataframe se pasa a la función también.

**Sintaxis:**

```python
sns.regplot(x = 'header_1',y = 'header_2',data= df)
```

A continuación se muestra un gráfico de regresión de muestra.


![[Pasted image 20241230121637.png]]

**2. Gráfico de caja y bigotes**

Un gráfico de caja (o gráfico de caja y bigotes) muestra la distribución de datos cuantitativos de una manera que facilita las comparaciones entre variables o a través de niveles de una variable categórica. La caja muestra los cuartiles del conjunto de datos, mientras que los bigotes se extienden para mostrar el resto de la distribución, excepto por los puntos que se determinan como “valores atípicos”.

Considere la figura de interpretación del gráfico de caja y bigotes que se muestra a continuación.


![[Pasted image 20241230121659.png]]


El gráfico utiliza bigotes para representar el valor mínimo hasta el 25% de los datos del cuartil y del 75% del cuartil hasta el valor máximo. El rango entre el 25% del cuartil y el 75% del cuartil se considera como el rango intercuartílico. Los valores atípicos generalmente se clasifican como aquellos que están fuera de 1.5 veces el rango intercuartílico.

A continuación se muestra un gráfico de caja de muestra


![[Pasted image 20241230121722.png]]

**3. Gráfico de residuos**

Un gráfico de residuos se utiliza para mostrar la calidad de la regresión polinómica. Esta función regresará y sobre x como una regresión polinómica y luego dibujará un diagrama de dispersión de los residuos.  
Los residuos son las diferencias entre los valores observados de la variable dependiente y los valores predichos obtenidos del modelo de regresión. En otras palabras, un residuo es una medida de cuánto una línea de regresión se desvía verticalmente de un punto de datos, lo que significa qué tan lejos están las predicciones de los puntos de datos reales.

**Sintaxis:**

```python
sns.residplot(data=df,x='header_1', y='header_2')
```

Alternativamente:

```python
sns.residplot(x=df['header_1'], y=df['header_2'])
```


![[Pasted image 20241230121839.png]]

**4. Gráfico KDE**

Un gráfico de Estimación de Densidad Kernel (KDE) es un gráfico que crea una curva de distribución de probabilidad para los datos basada en su probabilidad de ocurrencia en un valor específico. Esto se crea para un único vector de información. Se utiliza en el curso para comparar las curvas probables de los datos reales con las de los datos predichos.

**Sintaxis:**


```python
sns.kdeplot(X)
```

A continuación se muestra un gráfico de ejemplo hecho para un conjunto aleatorio de valores.


![[Pasted image 20241230121924.png]]

**5. Gráfico de Distribución**

Este gráfico tiene la capacidad de combinar el histograma y los gráficos KDE. Este gráfico crea la curva de distribución utilizando los intervalos del histograma como referencia para la estimación. Opcionalmente, puedes mantener o descartar la visualización del histograma. En el contexto del curso, este gráfico se puede usar de manera intercambiable con el gráfico KDE.

**Sintaxis:**

```python
sns.distplot(X,hist=False)
```

Aquí, mantener el argumento `hist` como `True` trazaría el histograma junto con el gráfico de distribución. Ambas variaciones se muestran en la imagen a continuación.


![[Pasted image 20241230122012.png]]




# Correlación


En este texto, hablaremos de la correlación entre diferentes variables. La correlación es una métrica estadística utilizada para medir en qué medida las variables son interdependientes. En otras palabras, cuando observamos dos variables a lo largo del tiempo, nos interesa saber cómo un cambio en una de ellas afecta al cambio en la otra.

Por ejemplo, se sabe que fumar está relacionado con el cáncer de pulmón, ya que quienes fuman tienen una mayor probabilidad de desarrollar esta enfermedad. De manera similar, existe una correlación entre las variables paraguas y lluvia. Cuando hay más precipitaciones, más personas usan paraguas, mientras que si no llueve, es probable que las personas no lleven uno. Por lo tanto, podemos afirmar que los paraguas y la lluvia son interdependientes y están correlacionados. Sin embargo, es importante destacar que la correlación no implica causalidad. Aunque sabemos que existe una correlación entre el uso del paraguas y la lluvia, no tenemos suficiente información para determinar si el uso del paraguas causa la lluvia o si la lluvia es la que provoca el uso del paraguas.

En el campo de la ciencia de datos, normalmente nos enfocamos más en la correlación que en la causalidad. Veamos un ejemplo de correlación entre el tamaño del motor de un vehículo y su precio. Al visualizar estas dos variables mediante un diagrama de dispersión, podemos agregar una línea de regresión, que muestra la relación entre ambas. El objetivo principal de este gráfico es observar si el tamaño del motor influye en el precio del vehículo. En este caso, la línea que atraviesa los puntos de datos es bastante pronunciada, lo que indica que existe una relación lineal positiva entre el tamaño del motor y el precio. Es decir, a medida que aumenta el tamaño del motor, también lo hace el precio, lo que demuestra una correlación positiva entre ambas variables.

Otro ejemplo sería la relación entre las millas de carretera por galón y el precio del automóvil. Al observar este gráfico, podemos ver que cuando el valor de las millas por galón aumenta, el precio disminuye. Esto muestra que existe una relación lineal negativa entre estas dos variables. Aunque la relación es negativa, la pendiente de la línea es pronunciada, lo que sugiere que las millas por galón siguen siendo un buen indicador del precio. Por lo tanto, se dice que estas dos variables tienen una correlación negativa.

Por último, tenemos un ejemplo de una correlación débil. En este caso, tanto las RPM de pico bajas como las altas están asociadas con precios bajos y altos, respectivamente. Esto indica que no podemos utilizar las RPM para predecir el precio de manera confiable.

# Correlación - Estadísticas


# Prueba de Chi-Cuadrado para Variables Categóricas

### Introducción

La prueba de chi-cuadrado es un método estadístico utilizado para determinar si existe una asociación significativa entre dos variables categóricas. Esta prueba se utiliza ampliamente en diversos campos, incluyendo las ciencias sociales, el marketing y la atención sanitaria, para analizar datos de encuestas, resultados experimentales y estudios observacionales.

### Concepto

La prueba de chi-cuadrado es un método estadístico no paramétrico utilizado para examinar la asociación entre dos variables categóricas. Evalúa si las frecuencias de los resultados observados se desvían significativamente de las frecuencias esperadas, asumiendo que las variables son independientes. La prueba se basa en la distribución chi-cuadrado, que se aplica a datos de conteo y ayuda a determinar si alguna desviación observada podría haber surgido por azar.

#### Hipótesis Nula y Hipótesis Alternativa

La prueba de chi-cuadrado implica formular dos hipótesis:

Hipótesis Nula (𝐻0)(H0​) - Asume que no hay asociación entre las variables categóricas, lo que implica que cualquier diferencia observada se debe al azar.

Hipótesis Alternativa (H1)(H1​) - Asume que hay una asociación significativa entre las variables, indicando que las diferencias observadas no se deben solo al azar.

### Fórmula

La estadística chi-cuadrado se calcula usando la fórmula:


![[Pasted image 20241231075121.png]]



donde  
OiOi​ es la frecuencia observada para la categoría ii.  
EiEi​ es la frecuencia esperada para la categoría ii, calculada como:


![[Pasted image 20241231075138.png]]


La suma se realiza sobre todas las celdas en la tabla de contingencia.

La estadística chi-cuadrado calculada se compara luego con un valor crítico de la tabla de distribución chi-cuadrado. Esta tabla proporciona valores críticos para diferentes grados de libertad (df)(df) y niveles de significancia (α)(α).

Los grados de libertad para la prueba se calculan como:

![[Pasted image 20241231075155.png]]

donde rr es el número de filas y cc es el número de columnas en la tabla.

### Aplicaciones

1. **Investigación de Mercados:** Analizando la asociación entre la demografía de los clientes y las preferencias de productos.
2. **Salud:** Estudiando la relación entre las características de los pacientes y la incidencia de enfermedades.
3. **Ciencias Sociales:** Investigando el vínculo entre factores sociales (por ejemplo, nivel educativo) y resultados de comportamiento (por ejemplo, patrones de votación).
4. **Educación:** Examinando la conexión entre los métodos de enseñanza y el rendimiento estudiantil.
5. **Control de Calidad:** Evaluando la asociación entre las condiciones de fabricación y los defectos de productos.


### Ejemplo Práctico - Correlación Débil

Supongamos que un investigador quiere determinar si hay una asociación entre el género (masculino, femenino) y la preferencia por un nuevo producto (gustar, no gustar). El investigador encuesta a 100 personas y registra los siguientes datos:

![[Pasted image 20241231075226.png]]

**Paso 1: Calcular Frecuencias Esperadas**

Usando la fórmula para frecuencias esperadas:


![[Pasted image 20241231075244.png]]

**Paso 2: Calcular la Estadística Chi-Cuadrado**


![[Pasted image 20241231075302.png]]


**Paso 3: Determinar los Grados de Libertad**



![[Pasted image 20241231075324.png]]


**Paso 4: Interpretar el Resultado**

Usando una tabla de distribución chi-cuadrado, comparamos el valor chi-cuadrado calculado (1.008) con el valor crítico en un grado de libertad y un nivel de significancia (por ejemplo, 0.05). El valor crítico, determinado a partir de las tablas de distribución chi-cuadrado, es aproximadamente 3.841.

Dado que 1.008 < 3.841, no rechazamos la hipótesis nula. Por lo tanto, no hay una asociación significativa entre el género y la preferencia por el producto en esta muestra.

### Ejemplo Práctico - Asociación Fuerte

Considera un estudio que investiga la relación entre el estado de fumador (fumador, no fumador) y la incidencia de enfermedades pulmonares (enfermedad, sin enfermedad). El investigador recopila datos de 200 individuos y registra la siguiente información:


![[Pasted image 20241231075341.png]]

**Paso 1: Calcular Frecuencias Esperadas**

Utilizando la fórmula para frecuencias esperadas:

![[Pasted image 20241231075412.png]]

**Paso 3: Determinar los Grados de Libertad**

![[Pasted image 20241231075432.png]]

donde:

- **r** es el número de filas en la tabla de contingencia (en este caso, el género: masculino, femenino, es decir, **2 filas**),
- **c** es el número de columnas en la tabla de contingencia (en este caso, la preferencia por el producto: gustar, no gustar, es decir, **2 columnas**).

**Paso 4: Interpretar el Resultado**

Utilizando una tabla de distribución chi-cuadrado, comparamos el valor chi-cuadrado calculado (44.33) con el valor crítico en un grado de libertad y un nivel de significancia (por ejemplo, 0.05), aproximadamente 3.841. Dado que 44.33 > 3.841, rechazamos la hipótesis nula. Esto indica una asociación significativa entre el estado de fumador y la incidencia de enfermedades pulmonares en esta muestra.

### Conclusión

La prueba de chi-cuadrado es una herramienta poderosa para analizar la relación entre variables categóricas. Al comparar las frecuencias observadas y esperadas, los investigadores pueden determinar si hay una asociación estadísticamente significativa, proporcionando valiosos conocimientos en diversas áreas de estudio.



### Recordatorio del contexto

El investigador quiere saber si hay una **asociación significativa** entre el **género** (masculino o femenino) y la **preferencia por un producto** (gustar o no gustar). Después de calcular el valor de **chi-cuadrado** (que en este caso es 1.008), se debe comparar con un valor crítico de la distribución de chi-cuadrado para tomar una decisión sobre si **rechazar o no** la hipótesis nula.

### Paso 4: Interpretación del resultado de la prueba

#### 1. ¿Qué es la **hipótesis nula**?

La **hipótesis nula** (denotada como H0H_0H0​) es la suposición de que **no hay ninguna relación** o **asociación** entre las variables que estamos analizando. En este caso, la hipótesis nula sería:

> No hay asociación entre el género y la preferencia por el producto.

#### 2. ¿Qué es la **hipótesis alternativa**?

La **hipótesis alternativa** (denotada como HAH_AHA​) es lo contrario de la hipótesis nula, es decir, lo que queremos probar. En este caso, la hipótesis alternativa sería:

> Hay una asociación entre el género y la preferencia por el producto.

#### 3. ¿Cómo se calcula el **valor de chi-cuadrado**?

El **valor de chi-cuadrado** se calcula usando la fórmula de chi-cuadrado para tablas de contingencia. En este caso, el valor obtenido fue **1.008**. Este valor refleja la diferencia entre los valores observados (los datos reales en la tabla) y los valores esperados (lo que esperaríamos si no hubiera ninguna asociación).

#### 4. ¿Qué es el **valor crítico** de chi-cuadrado?

El **valor crítico** es un número que se obtiene de una **tabla de distribución chi-cuadrado**. Este valor depende de:

- Los **grados de libertad** (df) de la prueba (que calculamos previamente y son 1),
- El **nivel de significancia** (α\alphaα), que comúnmente se toma como 0.05 para una prueba de hipótesis. Esto significa que estamos dispuestos a aceptar un 5% de error en nuestros resultados.

En una tabla de distribución chi-cuadrado, para 1 grado de libertad y un nivel de significancia de 0.05, el **valor crítico** es aproximadamente **3.841**.

#### 5. ¿Cómo se hace la **comparación** entre el valor de chi-cuadrado y el valor crítico?

Ahora que tenemos el valor calculado de chi-cuadrado (1.008) y el valor crítico (3.841), comparamos ambos:

- Si el valor calculado de chi-cuadrado es **mayor o igual** al valor crítico, **rechazamos** la hipótesis nula.
- Si el valor calculado de chi-cuadrado es **menor** que el valor crítico, **no rechazamos** la hipótesis nula.

En este caso:

- El valor de chi-cuadrado calculado es **1.008**.
- El valor crítico para un nivel de significancia de 0.05 y 1 grado de libertad es **3.841**.

**1.008 < 3.841**, por lo tanto, **no rechazamos la hipótesis nula**.

#### 6. ¿Qué significa esto?

Dado que el valor calculado de chi-cuadrado (1.008) es menor que el valor crítico (3.841), **no rechazamos la hipótesis nula**. Esto significa que **no hay suficiente evidencia** para concluir que existe una asociación significativa entre el género y la preferencia por el producto en esta muestra.

### Conclusión:

La prueba de chi-cuadrado indica que, con un nivel de significancia de 0.05, no podemos afirmar que haya una relación estadísticamente significativa entre el género y la preferencia por el producto. Los resultados sugieren que **el género no está asociado de manera significativa con la preferencia por el producto** en este caso.

Es importante destacar que esto **no prueba** que no haya ninguna relación, solo que con los datos disponibles y el nivel de significancia elegido, no encontramos evidencia suficiente para rechazar la hipótesis nula.




Sí, en las pruebas de chi-cuadrado y en otras pruebas estadísticas, se utilizan **tablas de distribución** (como la tabla de chi-cuadrado) para determinar qué valor de chi-cuadrado se considera significativo y, a partir de ello, establecer **rangos de significancia**.

Te explico cómo se puede interpretar el **valor p** y cómo los rangos de chi-cuadrado pueden determinar si los resultados son significativos o no.

### 1. **Nivel de significancia (α)**

El **nivel de significancia** (denotado como α\alpha) es un umbral que se utiliza para determinar si el resultado es estadísticamente significativo. El valor más común es **0.05** (5%), lo que significa que aceptamos un 5% de probabilidad de cometer un error tipo I (rechazar una hipótesis nula que es verdadera).

Si el valor p es **menor que 0.05**, rechazamos la hipótesis nula. Si el valor p es **mayor que 0.05**, no rechazamos la hipótesis nula.

### 2. **¿Qué es el valor p?**

El valor p es la **probabilidad** de obtener un resultado al menos tan extremo como el observado, dado que la hipótesis nula es cierta. En el caso de la prueba de chi-cuadrado, el valor p se obtiene a partir del **valor chi-cuadrado calculado** y los **grados de libertad (df)**.

Si el valor p es menor que el nivel de significancia α\alpha, se considera que los resultados son estadísticamente significativos, es decir, hay suficiente evidencia para rechazar la hipótesis nula.

### 3. **Tablas de chi-cuadrado:**

Las **tablas de chi-cuadrado** proporcionan los valores críticos de chi-cuadrado para diferentes combinaciones de **grados de libertad** (df) y niveles de significancia. Dependiendo del número de **grados de libertad (df)** de la prueba, y el nivel de significancia que hayas seleccionado (por ejemplo, 0.05), las tablas indican el **valor crítico de chi-cuadrado** que debes comparar con el valor calculado de chi-cuadrado.

### 4. **Interpretación de los valores de chi-cuadrado:**

Para entender mejor cómo interpretar los resultados, considera el siguiente ejemplo de una tabla de chi-cuadrado con **1 grado de libertad** (df = 1), que es el caso de tu problema:

|Nivel de significancia (α)|Valor crítico de chi-cuadrado (df=1)|
|---|---|
|0.10|2.71|
|0.05|3.841|
|0.01|6.635|

**Interpretación:**

- Si el valor calculado de chi-cuadrado es **mayor que el valor crítico** en la tabla, entonces **rechazamos la hipótesis nula** y concluimos que hay una asociación significativa entre las variables.
- Si el valor calculado de chi-cuadrado es **menor que el valor crítico**, **no rechazamos la hipótesis nula**. En este caso, no hay suficiente evidencia para afirmar que hay una asociación significativa.

### Ejemplo práctico con tu resultado:

En tu caso, el valor de chi-cuadrado calculado fue **1.008** con **1 grado de libertad (df = 1)**. Comparamos esto con el valor crítico de **3.841** para un nivel de significancia de **0.05**.

**1.008 < 3.841**, por lo que no rechazamos la hipótesis nula. Esto significa que **no hay una asociación significativa entre el género y la preferencia por el producto** en esta muestra.

### 5. **¿Cómo se determinan los rangos de significancia?**

Para establecer los **rangos de significancia** en términos de chi-cuadrado, podemos considerar los valores del **valor p** asociado al chi-cuadrado. Un **valor p** bajo (menor que 0.05) indica que la diferencia observada es **estadísticamente significativa**, mientras que un **valor p** alto (mayor que 0.05) sugiere que **no hay una diferencia significativa**.

### Ejemplo de interpretación del valor p y los rangos de significancia:

- **Valor p < 0.05**: Esto indica que el valor calculado de chi-cuadrado es suficientemente grande para rechazar la hipótesis nula, lo que implica una relación significativa.
- **Valor p ≥ 0.05**: Esto significa que el valor calculado de chi-cuadrado no es suficiente para rechazar la hipótesis nula, lo que implica que no hay una relación significativa.

### 6. **Resumen:**

- Los **valores críticos** de chi-cuadrado dependen de los **grados de libertad (df)** y del nivel de significancia (α) que elijas.
- Si el valor calculado de chi-cuadrado es mayor que el valor crítico de la tabla (o si el valor p es menor que 0.05), se rechaza la hipótesis nula.
- Si el valor calculado de chi-cuadrado es menor que el valor crítico (o si el valor p es mayor que 0.05), no se rechaza la hipótesis nula.

En tu caso, **1.008** es menor que **3.841**, por lo que **no rechazamos** la hipótesis nula y concluimos que no hay evidencia suficiente para afirmar que existe una relación significativa entre el género y la preferencia por el producto en la muestra.



![[Pasted image 20241231113249.png]]


![[Pasted image 20241231113257.png]]

### 3. Seleccione el gráfico de dispersión con una correlación débil:



![[Pasted image 20241231113333.png]]



![[Pasted image 20241231113540.png]]






















