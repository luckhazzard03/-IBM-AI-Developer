

El preprocesamiento de datos es un paso fundamental en el análisis de datos. Consiste en transformar o mapear datos desde un formato sin procesar a otro más adecuado para su análisis posterior. Este proceso es comúnmente conocido como limpieza o procesamiento de datos, aunque pueden emplearse otros términos similares. A lo largo de este módulo, exploraremos varias técnicas esenciales para llevar a cabo este preprocesamiento de manera eficaz.

En primer lugar, abordaremos cómo identificar y gestionar los valores faltantes en los datos. Los valores faltantes son aquellos que se encuentran vacíos o ausentes en el conjunto de datos. Es fundamental manejar estos valores de manera adecuada, ya que pueden afectar la calidad del análisis posterior. A continuación, nos centraremos en los diferentes formatos de los datos. Es común que los datos provengan de diversas fuentes y, por lo tanto, estén en distintos formatos, unidades o convenciones. Aquí, veremos cómo estandarizar estos datos usando herramientas en Python, específicamente con la librería Pandas, para convertirlos a un formato común, asegurando su coherencia y facilitar su manipulación.

Otro aspecto crucial del preprocesamiento es la normalización de datos. Las columnas numéricas pueden tener rangos de valores muy dispares, lo que hace que una comparación directa entre ellas no sea significativa. La normalización busca resolver este problema al agrupar los datos en un rango común, lo que permite comparaciones más útiles. Nos enfocaremos en técnicas específicas como el centrado y el escalado de datos, que ajustan los valores numéricos para que tengan características comparables.

A continuación, abordaremos el tema del agrupamiento de datos, que es una técnica utilizada para crear categorías más grandes a partir de un conjunto de valores numéricos. Este proceso es particularmente útil cuando se desea comparar distintos grupos de datos de forma más generalizada. Finalmente, discutiremos las variables categóricas y cómo transformarlas en variables numéricas para facilitar el modelado estadístico. Este paso es fundamental para la preparación de datos destinados a algoritmos de aprendizaje automático, que generalmente requieren variables numéricas para su funcionamiento.

En Python, las operaciones de preprocesamiento suelen realizarse a nivel de columnas dentro de un marco de datos. Cada fila de una columna representa una muestra o un caso específico, como por ejemplo, un automóvil usado en una base de datos. Para acceder a los datos de una columna, basta con especificar su nombre. Por ejemplo, se puede acceder a una columna denominada "simbología" o "estilo del cuerpo". Cada columna en un marco de datos de Pandas se considera una serie, lo que facilita su manipulación. Existen diversas formas de manipular estos marcos de datos en Python, como añadir un valor constante a cada entrada de una columna. Por ejemplo, si se desea añadir 1 a cada valor de la columna "simbología", simplemente se puede utilizar un comando específico que modifique todos los valores de esa columna de forma automática.

# Tratar con valores perdidos en Python

El problema de los valores faltantes es una situación común en el manejo de datos, y hay diversas estrategias para gestionarlos. Un valor faltante ocurre cuando no se almacena información para una característica específica de una observación en particular. Estos valores ausentes pueden aparecer en los datos como signos de interrogación, "N/A", ceros o celdas en blanco. Un ejemplo frecuente es el valor **NaN** (Not a Number), que representa un valor faltante en muchos conjuntos de datos.

Existen varias formas de gestionar los valores faltantes, y la mejor estrategia depende del contexto y la naturaleza de los datos. Una opción es intentar contactar con la persona o el grupo que recopiló los datos para verificar cuál podría ser el valor real de la observación faltante. Sin embargo, esto no siempre es posible, por lo que se deben considerar otras soluciones. Una de ellas es eliminar las observaciones que contienen valores faltantes. En este caso, se puede optar por eliminar toda la variable (columna) que contiene valores faltantes o solo las filas con datos incompletos. Si las observaciones con valores faltantes son pocas, eliminar esas filas generalmente no afectará significativamente al análisis.

Una alternativa es reemplazar los datos faltantes, lo que permite conservar el conjunto de datos completo sin perder información. Aunque esta técnica puede ser menos precisa, ya que se debe hacer una suposición sobre cuál sería el valor correcto, es una opción común. Un enfoque estándar es reemplazar los valores faltantes por el valor promedio de la columna correspondiente. Por ejemplo, si en una columna de pérdidas normalizadas faltan algunos valores y el promedio de los datos disponibles es 4500, se puede reemplazar los valores faltantes con ese promedio, aproximando los datos faltantes a ese valor.

Sin embargo, este enfoque solo es aplicable a variables numéricas. En el caso de variables categóricas, como el tipo de combustible, no tiene sentido calcular un promedio, ya que los valores no son numéricos. En tales casos, una posible solución es reemplazar los valores faltantes por el valor más frecuente o el "modo", como por ejemplo, el tipo de combustible más común (por ejemplo, gasolina).

En situaciones más complejas, si se dispone de información adicional sobre los datos faltantes, se puede hacer una suposición más informada. Por ejemplo, si se sabe que los valores faltantes suelen corresponder a coches antiguos, se puede utilizar el conocimiento de que las pérdidas normalizadas de los coches viejos son significativamente más altas que las de los vehículos más nuevos, y reemplazar los valores faltantes con un valor adecuado para ese grupo.

En algunos casos, puede ser útil simplemente dejar los datos faltantes tal como están. Si por alguna razón los valores faltantes no afectan demasiado al análisis o si la ausencia de datos tiene un significado particular, se puede optar por mantenerlos en su estado original.

En cuanto a la implementación en Python, la librería Pandas ofrece varias herramientas para tratar los valores faltantes. Una de ellas es el método **dropna()**, que permite eliminar filas o columnas que contienen valores faltantes. Al usar este método, se puede especificar el parámetro `axis` para indicar si se desea eliminar filas (`axis=0`) o columnas (`axis=1`). Por ejemplo, si una columna de precios contiene valores faltantes y estos son cruciales para el análisis, se pueden eliminar las filas que no contienen un precio indicado utilizando `dataframe.dropna()`. Si se quiere modificar directamente el conjunto de datos, se puede añadir el parámetro `inplace=True` para que la operación sea permanente.

Otra opción es reemplazar los valores faltantes por un valor calculado. Para ello, Pandas proporciona el método **replace()**. Por ejemplo, si se desea reemplazar los valores faltantes de una columna por el promedio de esa columna, primero se calcula la media y luego se utiliza el método **replace()** para sustituir los valores **NaN** por ese valor calculado. Esta es una forma simple de manejar los valores faltantes, pero también se pueden emplear técnicas más avanzadas, como reemplazar los valores faltantes por el promedio del grupo al que pertenece la observación, en lugar de utilizar el promedio general.

En resumen, en Python, podemos manejar los valores faltantes eliminando las filas o columnas que los contienen, o reemplazándolos por valores calculados, como la media o el modo. Sin embargo, siempre es importante considerar todas las opciones disponibles y elegir la más adecuada en función de las características del conjunto de datos y los objetivos del análisis.




# Formateo de datos en Python


En el análisis de datos, uno de los problemas más comunes es tratar con datos que tienen diferentes formatos, unidades y convenciones. Esto ocurre porque los datos suelen ser recopilados por distintas personas, desde diversas fuentes, y pueden almacenarse en distintos formatos. El formateo de datos es un paso crucial en el preprocesamiento, ya que consiste en estandarizar la representación de los datos para permitir comparaciones significativas y facilitar su análisis posterior. La limpieza de datos incluye este proceso de formateo, que garantiza que los datos sean consistentes, coherentes y fáciles de entender.

Por ejemplo, en el caso de una variable que representa la ciudad de Nueva York, diferentes personas pueden escribirla de formas variadas, como "N.Y.", "Ny", "NY" o "New York". En algunos casos, estas diferencias pueden ser útiles para ciertos análisis, como detectar fraudes o patrones de comportamiento, donde una forma específica de escribir "Nueva York" podría indicar algo relevante. Sin embargo, en la mayoría de los casos, lo que se busca es tratar estos datos de forma coherente, para analizarlos de manera más eficiente y con mayor precisión. Esto implica que, en lugar de tratar cada forma distinta como un dato independiente, las distintas representaciones de la ciudad deben unificarse a un solo formato.

En el contexto de un conjunto de datos de vehículos usados, podríamos encontrarnos con una columna que indica el consumo de combustible de los autos en términos de "millas urbanas por galón". Sin embargo, si trabajamos en un país que utiliza el sistema métrico, puede ser necesario convertir estos valores a "litros por cada 100 kilómetros". Para hacer esta conversión, podemos aplicar una fórmula matemática simple: dividir 235 entre los valores de la columna de "millas por galón". Esta conversión se puede realizar fácilmente en Python usando una sola línea de código. Además, después de hacer la conversión, es importante cambiar el nombre de la columna para reflejar la nueva unidad de medida, lo que se puede hacer mediante el método `rename()` de Pandas.

Un problema adicional que podemos encontrar al trabajar con datos es el tipo de datos asignado a una columna. A veces, al importar un conjunto de datos a Python, el tipo de datos de una columna puede ser incorrecto. Por ejemplo, podríamos observar que una columna de precios, que debería contener números enteros o flotantes, está siendo tratada como un objeto (un tipo de dato que generalmente se usa para cadenas de texto). Esto puede generar problemas durante el análisis, ya que los modelos podrían interpretar estos datos de forma incorrecta, e incluso datos válidos podrían ser tratados como faltantes.

En Pandas, existen varios tipos de datos, como objetos (que corresponden a texto), `Int64` (para números enteros), y `float` (para números decimales). Para identificar el tipo de datos de cada columna en un conjunto de datos, se puede utilizar el método `dtypes` del DataFrame, lo que nos permite verificar si cada columna tiene el tipo de datos esperado. Si encontramos que una columna tiene un tipo de datos incorrecto, podemos usar el método `astype()` para convertir la columna a un tipo adecuado. Por ejemplo, si la columna de precios está siendo tratada como un objeto, podemos convertirla a tipo entero o flotante utilizando `astype("int")` o `astype("float")`, según lo que sea más adecuado para el análisis posterior.

En resumen, cuando trabajamos con datos en Python, es esencial asegurarnos de que los datos estén en un formato uniforme, con unidades y convenciones consistentes. Además, debemos revisar y corregir los tipos de datos de las columnas para que coincidan con los valores que estamos analizando. Esto garantizará que los modelos y las operaciones estadísticas se realicen correctamente y que los resultados del análisis sean válidos y útiles.


# Normalización de datos en Python


En este video, hablaremos sobre la normalización de datos, una técnica crucial en el preprocesamiento de datos. La normalización tiene como objetivo ajustar las variables de un conjunto de datos para que sus valores estén dentro de un rango coherente. Esto facilita la comparación entre variables con diferentes escalas y asegura que ninguna variable domine a las demás en los análisis posteriores.

Por ejemplo, en un conjunto de datos de vehículos usados, podemos observar que la longitud de los vehículos varía entre 150 y 250, mientras que la anchura y la altura varían entre 50 y 100. Si no normalizamos estas variables, los análisis posteriores podrían verse influenciados por los rangos desiguales de las características. La normalización ayuda a hacer que el impacto de cada variable sea similar, lo que es particularmente útil cuando realizamos análisis estadísticos o modelos de machine learning.

Otro ejemplo para entender la importancia de la normalización es el análisis de dos características, como la edad e ingresos. La edad oscila entre 0 y 100 años, mientras que los ingresos varían entre 0 y 500,000. Dado que los ingresos son 1000 veces mayores que la edad, cuando realizamos un análisis de regresión lineal, los ingresos tendrán una mayor influencia sobre el modelo, aunque no necesariamente sean un predictor más importante. Para evitar este sesgo, podemos normalizar ambas características, llevándolas a un rango de 0 a 1. Esto asegura que ambas características tengan una influencia similar en el modelo.

Existen varias técnicas para normalizar los datos. Aquí describiremos tres métodos principales:

1. **Escalado de características simple:** Este método divide cada valor de la variable entre el valor máximo de esa característica. Como resultado, los nuevos valores estarán entre 0 y 1.
    
2. **Método de mínimo-máximo:** Este enfoque toma cada valor de la variable, le resta el valor mínimo de la entidad y luego lo divide por el rango de la variable (el valor máximo menos el valor mínimo). Los resultados también estarán entre 0 y 1.
    
3. **Puntuación Z o puntuación estándar:** En este método, para cada valor, se resta la media de la variable (μ) y luego se divide por la desviación estándar (σ). Esto da como resultado valores que generalmente oscilan entre -3 y 3, aunque pueden ser mayores o menores.
    

Para aplicar estos métodos, tomemos como ejemplo la característica de "longitud" en nuestro conjunto de datos. Con el método de escalado simple, simplemente dividimos cada valor de la columna de longitud por el valor máximo de esa columna. En Pandas, esto se puede hacer de manera sencilla usando el método `max()`.

El método mínimo-máximo se aplica restando el valor mínimo de la columna de longitud a cada valor y luego dividiendo por el rango de la columna (el valor máximo menos el valor mínimo). Finalmente, con el método de puntuación Z, restamos la media de la longitud de cada valor y dividimos por la desviación estándar, que se obtiene usando los métodos `mean()` y `std()` de Pandas.

En resumen, la normalización de datos es un paso fundamental para garantizar que todas las variables tengan un impacto equilibrado en los análisis y modelos posteriores. Al elegir el método adecuado de normalización, podemos mejorar la precisión y la eficacia de nuestros modelos y análisis estadísticos.

# Convertir variables categóricas en variables cuantitativas en Python


En este video, analizaremos cómo convertir variables categóricas en variables cuantitativas en Python. La mayoría de los modelos estadísticos no pueden procesar objetos o cadenas de texto como entrada; en su lugar, requieren datos numéricos para el entrenamiento del modelo. En un conjunto de datos sobre automóviles, por ejemplo, la variable "tipo de combustible" es categórica y tiene dos valores posibles: "gasolina" y "diésel", ambos representados como cadenas. Para realizar un análisis más detallado y permitir que los modelos trabajen con estos datos, es necesario convertir estas variables en un formato numérico.

Para ello, una de las técnicas más comunes es la **codificación en caliente** (one-hot encoding). Esto implica la creación de nuevas variables binarias (0 o 1) para cada categoría de la variable original. En el caso de la variable "tipo de combustible", que tiene dos valores posibles (gasolina y diésel), creamos dos nuevas columnas: una para "gasolina" y otra para "diésel". Cuando un valor en la variable original corresponde a una de las categorías, asignamos 1 a la nueva columna correspondiente y 0 a la otra. Por ejemplo, si el tipo de combustible de un automóvil es "diésel", asignamos 1 a la columna "diésel" y 0 a la columna "gasolina". De manera similar, si el tipo de combustible es "gasolina", asignamos 1 a la columna "gasolina" y 0 a la columna "diésel".

En Python, transformar variables categóricas en variables ficticias es un proceso sencillo utilizando la biblioteca **Pandas**. Usando el método `pd.get_dummies()`, podemos tomar la columna que contiene la variable categórica, como en el caso del tipo de combustible, y convertirla automáticamente en un conjunto de columnas binarias, cada una representando una categoría distinta. Al aplicar este método, obtendremos un nuevo marco de datos donde cada fila tendrá un 1 en la columna correspondiente a la categoría del combustible y 0 en la otra.

Este proceso convierte las variables categóricas en variables numéricas que pueden ser fácilmente utilizadas en modelos estadísticos o de machine learning.


- El formateo de datos es fundamental para que los datos procedentes de diversas fuentes sean coherentes y comparables.
    
- Dominar las técnicas en Python para convertir unidades de medida, como transformar "millas urbanas por galón" a "litros urbanos por cada 100 kilómetros" para facilitar la comparación y el análisis.
    
- Adquiera habilidades para identificar y corregir los tipos de datos en Python, asegurándose de que los datos se representan con precisión para los análisis estadísticos posteriores.
    
- La normalización de datos ayuda a que las variables sean comparables y a eliminar los sesgos inherentes a los modelos estadísticos.
    
- Puede aplicar Feature Scaling, Min-Max y Z-Score para normalizar los datos y aplicar cada técnica en Python utilizando los métodos de pandas.
    
- El binning es un método de preprocesamiento de datos para mejorar la precisión del modelo y la visualización de los datos.
    
- Ejecute técnicas de binning en Python utilizando los métodos "linspace" de numpy y "cut" de pandas, en particular para variables numéricas como "price"
    
- Utilice los histogramas para visualizar la distribución de los datos bindeados y obtener información sobre las distribuciones de las características.
    
- Los modelos estadísticos suelen requerir entradas numéricas, por lo que es necesario convertir variables categóricas como "tipo de combustible" en formatos numéricos.
    
- Puede implementar la técnica de codificación one-hot en Python utilizando el método **get_dummies** de pandas para transformar las variables categóricas en un formato adecuado para los modelos de aprendizaje automático.


![[Pasted image 20241227105625.png]]


![[Pasted image 20241227105633.png]]




Aquí tienes el contenido organizado en un cuadro:

|**Paquete/Método**|**Descripción**|**Ejemplo de código**|
|---|---|---|
|**Reemplazar datos faltantes con frecuencia**|Reemplazar los valores faltantes del atributo del conjunto de datos con la entrada más común en la columna.|`MostFrequentEntry = df['attribute_name'].value_counts().idxmax()``df['attribute_name'].replace(np.nan, MostFrequentEntry, inplace=True)`|
|**Reemplazar datos faltantes con la media**|Reemplazar los valores faltantes del atributo del conjunto de datos con la media de todas las entradas en la columna.|`AverageValue=df['attribute_name'].astype(<data_type>).mean(axis=0)``df['attribute_name'].replace(np.nan, AverageValue, inplace=True)`|
|**Corregir los tipos de datos**|Corregir los tipos de datos de las columnas en el dataframe.|`df[['attribute1_name', 'attribute2_name', ...]] = df[['attribute1_name', 'attribute2_name', ...]].astype('data_type')`_#data_type es int, float, char, etc._|
|**Normalización de datos**|Normalizar los datos en una columna de modo que los valores estén restringidos entre 0 y 1.|`df['attribute_name'] = df['attribute_name']/df['attribute_name'].max()`|
|**Clasificación**|Crear intervalos de datos para un mejor análisis y visualización.|`bins = np.linspace(min(df['attribute_name']), max(df['attribute_name']), n)`_n es el número de contenedores necesarios_ `GroupNames = ['Group1','Group2',...]``df['binned_attribute_name'] = pd.cut(df['attribute_name'], bins, labels=GroupNames, include_lowest=True)`|
|**Cambiar nombre de columna**|Cambiar el nombre de la etiqueta de una columna del dataframe.|`df.rename(columns={'old_name':'new_name'}, inplace=True)`|
|**Variables Indicadoras**|Crear variables indicadoras para datos categóricos.|`dummy_variable = pd.get_dummies(df['attribute_name'])``df = pd.concat([df, dummy_variable], axis=1)`|

Este cuadro resume las diferentes técnicas para manipular datos en Python usando la biblioteca Pandas.



![[Pasted image 20241227112507.png]]


![[Pasted image 20241227112516.png]]


![[Pasted image 20241227112525.png]]















