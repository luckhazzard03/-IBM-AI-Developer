
# HTML para Webscraping



El lenguaje de marcado de hipertexto (HTML) es fundamental para el webscraping, ya que muchas páginas web contienen datos útiles como precios de inmuebles o soluciones a preguntas de codificación. Por ejemplo, Wikipedia es un repositorio global de información accesible a través de HTML. Si tienes conocimientos de HTML, puedes utilizar Python para extraer esta información. HTML es el lenguaje de marcado que estructuran las páginas web, y consiste en texto rodeado por etiquetas. Las etiquetas indican cómo debe mostrarse el contenido en el navegador. Los datos que necesitamos suelen estar contenidos dentro de estas etiquetas.

Por ejemplo, el elemento `<html>` es el elemento raíz de una página HTML, mientras que el elemento `<head>` contiene metainformación sobre la página. El cuerpo de la página, donde se encuentran los datos de interés, está definido dentro del elemento `<body>`. Dentro de este cuerpo, las etiquetas `<h3>` se utilizan para definir encabezados de tercer nivel, como los nombres de los jugadores, y las etiquetas `<p>` se utilizan para definir párrafos, como los salarios de los jugadores.

![[Pasted image 20241219110250.png]]



Cada etiqueta HTML tiene una estructura que incluye un nombre de etiqueta (como `<a>` para enlaces) y puede contener atributos, como un enlace a otra página web. La etiqueta de anclaje `<a>` define un hipervínculo, y el atributo `href` contiene la URL de destino. Es útil pensar en cada etiqueta como una clase en Python, y cada instancia de esa etiqueta como un objeto.

Además, las páginas web reales pueden ser mucho más complejas, y puedes inspeccionar el HTML de una página utilizando herramientas como el "Inspector" en los navegadores. Es importante notar que también hay otros tipos de contenido, como CSS y JavaScript, que no se abordarán en este curso.

El documento HTML puede visualizarse como un árbol, con las etiquetas como nodos. Por ejemplo, la etiqueta `<html>` es el nodo principal, y tiene elementos secundarios como `<head>` y `<body>`. A su vez, la etiqueta `<head>` tiene un hijo llamado `<title>`, y el `<body>` puede contener otras etiquetas como `<h3>` y `<p>`, que son hermanas entre sí.

En cuanto a las tablas HTML, se definen con la etiqueta `<table>`. Las filas de la tabla se definen con la etiqueta `<tr>`, y dentro de cada fila, las celdas se definen con la etiqueta `<td>`. Las primeras filas y celdas suelen contener encabezados o datos importantes, y las filas siguientes contienen los datos correspondientes.

Con estos conocimientos básicos de HTML, puedes comenzar a extraer datos de una página web utilizando herramientas y técnicas de webscraping.


# Webscraping

Después de ver este video, serás capaz de definir el web scraping, entender el papel de los objetos BeautifulSoup, aplicar el método find_all y crear un webscrape de un sitio web. Imagina que te piden analizar cientos de puntos de datos para encontrar a los mejores jugadores de un equipo deportivo. ¿Comenzarías a copiar y pegar manualmente la información de diferentes sitios web en una hoja de cálculo? ¿Pasarías horas intentando encontrar los datos correctos, solo para rendirte porque la tarea resulta demasiado abrumadora? Aquí es donde el web scraping puede ser de gran ayuda. El web scraping es un proceso que permite extraer automáticamente información de un sitio web, y se puede realizar de manera rápida, en cuestión de minutos, usando solo un poco de código en Python y la ayuda de dos módulos: Requests y BeautifulSoup.


![[Pasted image 20241219111108.png]]



Para empezar, importamos BeautifulSoup y almacenamos el HTML de la página web como una cadena en una variable llamada HTML. Luego, pasamos esta cadena al constructor BeautifulSoup, lo que nos permite obtener el objeto BeautifulSoup, llamado "soup", que representa el documento como una estructura de datos anidada.

BeautifulSoup representa el HTML como un conjunto de objetos organizados en forma de árbol, y se utilizan métodos para analizar este HTML. Al revisar el objeto BeautifulSoup (soup), podemos observar que cada "etiqueta" corresponde a una etiqueta HTML en el documento original, como por ejemplo, la etiqueta `<h3>`. Si hay más de una etiqueta con el mismo nombre, BeautifulSoup seleccionará el primer elemento con esa etiqueta. En el caso de los nombres de los jugadores, como el de LeBron James, el nombre está encerrado dentro de una etiqueta `<b>` que lo pone en negrita. Usamos esta representación en forma de árbol para extraer la información. En el objeto de etiqueta, podemos acceder a elementos secundarios de la etiqueta o navegar por la estructura del árbol. Por ejemplo, podemos navegar hacia arriba en el árbol utilizando el atributo `parent` o hacia los hermanos de una etiqueta con el atributo `next_sibling`.


![[Pasted image 20241219111143.png]]


El método find_all es una herramienta clave en el web scraping. Este método actúa como un filtro que permite buscar etiquetas según su nombre, atributos o el texto que contienen. Al usar find_all, se puede buscar todos los descendientes de una etiqueta que coincidan con los filtros aplicados. Por ejemplo, si tienes una tabla con datos, puedes utilizar find_all para recuperar todas las filas de la tabla que coincidan con los criterios especificados. El resultado de este método es una lista iterable de Python, donde cada elemento es un objeto de etiqueta correspondiente a una fila en la tabla, incluyendo el encabezado.

![[Pasted image 20241219111212.png]]

![[Pasted image 20241219111226.png]]


![[Pasted image 20241219111306.png]]


![[Pasted image 20241219111343.png]]



Para iterar sobre las filas de una tabla, primero recorremos la lista de filas, luego aplicamos find_all a cada fila para obtener las celdas correspondientes. A través de este proceso, podemos extraer datos de manera eficiente de cada celda en cada fila, repitiendo el proceso para todas las filas de la tabla.
![[Pasted image 20241219111443.png]]



Para raspar una página web, también necesitamos la biblioteca de solicitudes. El primer paso es importar los módulos necesarios. Usamos el método `get` de la biblioteca Requests para descargar la página web, proporcionando la URL del sitio. A continuación, utilizamos el atributo `text` para obtener el contenido de la página y asignarlo a la variable "página". Luego, creamos un objeto BeautifulSoup llamado "soup" a partir de esta variable, lo que nos permitirá analizar el HTML de la página. Con esto, ya podemos comenzar a raspar la página web y extraer la información deseada.
![[Pasted image 20241219111537.png]]

![[Pasted image 20241219111602.png]]


