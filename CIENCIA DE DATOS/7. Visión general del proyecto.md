

Para este proyecto, asumirá el papel de un científico de datos / analista de datos que trabaja para una nueva empresa de inversión que ayuda a los clientes a invertir su dinero en acciones. Su trabajo consistirá en extraer datos financieros como el precio histórico de las acciones y los informes trimestrales de ingresos de diversas fuentes utilizando bibliotecas Python y webscraping sobre acciones populares. Tras recopilar estos datos, los visualizarás en un cuadro de mandos para identificar patrones o tendencias. Las acciones con las que trabajaremos son Tesla, Amazon, AMD y GameStop.

**Visualización de los análisis del cuadro de mandos**

Un cuadro de mandos suele ofrecer una visión de los indicadores clave de rendimiento de forma clara. Se practicará el análisis de un conjunto de datos y la extracción de indicadores clave de rendimiento. Se utilizarán avisos para apoyar el aprendizaje en el acceso y la visualización de datos en cuadros de mando. En esta tarea se incluirá el aprendizaje de cómo mostrar los indicadores clave de rendimiento en un cuadro de mando. Utilizaremos Plotly en este curso para la visualización de datos y no es un requisito para tomar este curso.

En el curso Python para Ciencia de Datos, IA y Desarrollo usted utilizó Skills Network Labs para los laboratorios prácticos.

Para este proyecto utilizará Skills Network Labs y Watson Studio. Skills Network Labs es un entorno sandbox para aprender y completar los laboratorios de los cursos. Mientras que Watson Studio, un componente de IBM Cloud Pak for Data, es un conjunto de herramientas y un entorno de colaboración para científicos de datos, analistas de datos, ingenieros de IA y aprendizaje automático y expertos de dominio para desarrollar y desplegar sus proyectos.

**Criterios de revisión**

Hay dos laboratorios prácticos sobre Extracción de datos de existencias y una tarea para completar. Se le evaluará completando dos cuestionarios y una tarea de revisión por pares. Los cuestionarios le evaluarán basándose en los resultados de los laboratorios prácticos. En la tarea de revisión por pares compartirá y realizará capturas de pantalla de los resultados de su tarea.



En este laboratorio, utilizará una biblioteca de Python para obtener datos financieros. Extraerás datos bursátiles históricos utilizando yfinance. A continuación se realizará un cuestionario para evaluar los resultados del laboratorio.

Para completar este laboratorio utilizarás JupyterLab ejecutándose en el entorno Cloud in Skills Network Labs. Para iniciar el cuaderno de laboratorio en una nueva pestaña del navegador, marque la casilla de abajo y haga clic en el botón **"Launch App"**.

En caso de que necesite descargar el cuaderno de laboratorio (archivo .ipynb) haga clic [AQUÍ](https://cf-courses-data.static.labs.skills.network/AaMNKtSmXxUUIzjBTqRfew/Final-Assignment%20Library-v2.ipynb "HERE") para descargar el cuaderno de laboratorio.


# La biblioteca de Python yfinance

La `yfinance` es una biblioteca de Python con una interfaz fácil de usar para descargar datos históricos del mercado desde Yahoo Finance. Te permite obtener precios históricos de acciones, dividendos y otros datos financieros para acciones, fondos cotizados en bolsa (ETFs) y otros valores.

Este ejemplo muestra código para usar `yfinance` para descargar precios históricos de acciones.

1. 1
2. 2
3. 3
4. 4
5. 5
6. 6
7. 7
8. 8

1. `import yfinance as yf`

3. `# Download historical data for a stock`
4. `msft = yf.Ticker("MSFT")`
5. `msft_data = msft.history(period="max")`

7. `# Display the downloaded data`
8. `msft_data.head()`

Copied!

**Explicación del código anterior:**

- Primero, importa la biblioteca `yfinance` usando el alias `yf`.
- Luego, crea un objeto `Ticker` para la acción de Microsoft (“MSFT”).
- Usa el método `history` del objeto Ticker para descargar los datos históricos de la acción. El parámetro `period` del método `history` especifica cuándo deseas descargar los datos. En este ejemplo, está configurado como `max` para descargar el máximo de datos históricos disponibles.

Aquí hay algunos de los posibles valores para el parámetro period y lo que representan:

- period="1d": Descargar 1 día de datos históricos.
- period="5d": Descargar 5 días de datos históricos.
- period="1mo": Descargar 1 mes de datos históricos.
- period="3mo": Descargar 3 meses de datos históricos.
- period="6mo": Descargar 6 meses de datos históricos.
- period="1y": Descargar 1 año de datos históricos.
- period="2y": Descargar 2 años de datos históricos.
- period="5y": Descargar 5 años de datos históricos.
- period="10y": Descargar 10 años de datos históricos.
- period="ytd": Descargar datos históricos desde el comienzo del año actual.
- period="max": Descargar todos los datos históricos disponibles.

Finalmente, imprimes los datos descargados usando la función `head`. Estos datos descargados mostrarán un marco de datos de Pandas que contiene los precios históricos de las acciones de Microsoft y otros datos financieros.

![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/Output1.png)



# Extracción de datos bursátiles mediante una biblioteca de Python


Este es un ejercicio introductorio de _web scraping_ con Beautiful Soup, donde puedes aprender cómo extraer datos de páginas web mediante Python. Aquí se explican varias técnicas para navegar y extraer información de un documento HTML.

### Parte del ejercicio:

1. **Objetivos**:
    
    - Aprender a utilizar `BeautifulSoup` para analizar documentos HTML.
    - Conocer cómo acceder y manipular las etiquetas HTML.
    - Aprender a filtrar contenido utilizando `find_all` y `find`.
2. **Instalación de bibliotecas**:
    
    - Se utilizan bibliotecas como `requests` para obtener contenido de la web, y `BeautifulSoup` para analizarlo y extraer información.
    
    ```python
    !mamba install bs4==4.10.0 -y
    !pip install lxml==4.6.4
    !mamba install html5lib==1.1 -y
    ```
    
3. **Estructura HTML básica**: Se presenta un ejemplo de HTML con una lista de jugadores y sus salarios. Luego se realiza un análisis de las etiquetas HTML utilizando `BeautifulSoup`:
    
    ```html
    <!DOCTYPE html>
    <html>
    <head>
    <title>Page Title</title>
    </head>
    <body>
    <h3><b id='boldest'>Lebron James</b></h3>
    <p> Salary: $ 92,000,000 </p>
    <h3> Stephen Curry</h3>
    <p> Salary: $85,000, 000 </p>
    <h3> Kevin Durant </h3>
    <p> Salary: $73,200, 000</p>
    </body>
    </html>
    ```
    
    Se puede analizar este HTML con `BeautifulSoup`:
    
    ```python
    from bs4 import BeautifulSoup
    html = """<html>...</html>"""
    soup = BeautifulSoup(html, "html.parser")
    print(soup.prettify())  # Mostrar el HTML formateado
    ```
    
4. **Navegación de objetos `Tag` y `NavigableString`**: `BeautifulSoup` crea objetos `Tag` que representan las etiquetas HTML, y `NavigableString` que representan el texto dentro de las etiquetas. Se pueden navegar y extraer estos objetos utilizando propiedades como `parent`, `next_sibling`, y `string`.
    
    - Ejemplo para obtener el nombre del primer jugador:
        
        ```python
        tag_object = soup.h3
        tag_child = tag_object.b  # Navegar a la etiqueta <b>
        ```
        
5. **Método `find_all`**: Utilizando `find_all`, se pueden buscar todas las ocurrencias de una etiqueta específica o un atributo en el HTML. Se muestra un ejemplo de cómo extraer filas de una tabla HTML:
    
    ```python
    table_rows = table_bs.find_all('tr')
    for row in table_rows:
        print(row)
    ```
    
6. **Obtención de datos de tablas HTML**: Para obtener datos de tablas de una página web, puedes usar `requests` para descargar la página y luego `BeautifulSoup` para analizarla. En el caso de un sitio con una tabla de colores, como el siguiente:
    
    ```python
    url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html"
    data = requests.get(url).text
    soup = BeautifulSoup(data, "html.parser")
    table = soup.find('table')
    
    for row in table.find_all('tr'):
        cols = row.find_all('td')
        color_name = cols[2].string
        color_code = cols[3].string
        print(f"{color_name} ---> {color_code}")
    ```
    
7. **Uso de Pandas para almacenar los resultados**: Los datos obtenidos se pueden almacenar en un `DataFrame` de `pandas` para analizarlos más fácilmente:
    
    ```python
    import pandas as pd
    population_data = pd.DataFrame(columns=["Rank", "Country", "Population", "Area", "Density"])
    
    for row in tables[table_index].tbody.find_all("tr"):
        col = row.find_all("td")
        if col:
            rank = col[0].text
            country = col[1].text
            population = col[2].text.strip()
            area = col[3].text.strip()
            density = col[4].text.strip()
            population_data = population_data.append({"Rank": rank, "Country": country, "Population": population, "Area": area, "Density": density}, ignore_index=True)
    ```
    

Este es un resumen del contenido de la lección, cubriendo los conceptos y ejemplos básicos que se presentan en el laboratorio de scraping web con BeautifulSoup y Pandas.






